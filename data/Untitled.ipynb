{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "470f37d8-ac29-4de7-bf8f-bf0a08fb6f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: playwright in c:\\users\\otavi\\anaconda3\\lib\\site-packages (1.54.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\otavi\\anaconda3\\lib\\site-packages (2.3.1)\n",
      "Requirement already satisfied: openpyxl in c:\\users\\otavi\\anaconda3\\lib\\site-packages (3.1.5)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\otavi\\anaconda3\\lib\\site-packages (2.9.0.post0)\n",
      "Requirement already satisfied: requests in c:\\users\\otavi\\anaconda3\\lib\\site-packages (2.32.3)\n",
      "Requirement already satisfied: pyee<14,>=13 in c:\\users\\otavi\\anaconda3\\lib\\site-packages (from playwright) (13.0.0)\n",
      "Requirement already satisfied: greenlet<4.0.0,>=3.1.1 in c:\\users\\otavi\\anaconda3\\lib\\site-packages (from playwright) (3.2.4)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\otavi\\anaconda3\\lib\\site-packages (from pyee<14,>=13->playwright) (4.14.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\otavi\\anaconda3\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\otavi\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\otavi\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\otavi\\anaconda3\\lib\\site-packages (from openpyxl) (1.1.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\otavi\\anaconda3\\lib\\site-packages (from python-dateutil) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\otavi\\anaconda3\\lib\\site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\otavi\\anaconda3\\lib\\site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\otavi\\anaconda3\\lib\\site-packages (from requests) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\otavi\\anaconda3\\lib\\site-packages (from requests) (2025.8.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['C:\\\\Users\\\\otavi\\\\anaconda3\\\\python.exe', '-m', 'playwright', 'install', 'chromium'], returncode=0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pip install playwright pandas openpyxl python-dateutil requests\n",
    "\n",
    "import sys, subprocess; subprocess.run([sys.executable, \"-m\", \"playwright\", \"install\", \"chromium\"], check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4e659638-1e56-4d38-b8f5-ca3f0461801f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# Angra Infra → Vehicle → Financials → métricas e séries (IRR/DPI/RVPI/TVPI) + PME(CDI)\n",
    "# Salva em: C:\\Users\\otaviobezerra\\OneDrive - FUNCEF\\Documentos\\PBI_COREM\\FIPS\\angra_infra_e_ip.xlsx\n",
    "\n",
    "# %%\n",
    "# Rode uma vez se precisar instalar:\n",
    "# %pip install playwright pandas openpyxl python-dateutil requests\n",
    "# import sys, subprocess; subprocess.run([sys.executable, \"-m\", \"playwright\", \"install\", \"chromium\"], check=True)\n",
    "\n",
    "# %%\n",
    "import os, re, math, json, asyncio, datetime as dt\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import requests\n",
    "from dateutil import parser as dtparse\n",
    "from playwright.async_api import async_playwright\n",
    "\n",
    "FUND_URL    = \"https://pebay.info/backoffice/fund/angra-infra\"\n",
    "OUTPUT_DIR  = r\"C:\\Users\\otavi\\OneDrive\\Documentos\\Estudos_2025\\COINP\\PROJECOES\\BANCODEDADOS\\FIP\"\n",
    "OUTPUT_XLSX = os.path.join(OUTPUT_DIR, \"angra_infra_e_ip.xlsx\")\n",
    "USER_DATA   = os.path.join(Path.home(), \".pw-angra\")  # contexto persistente (login fica salvo)\n",
    "HEADLESS    = False\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "NOW = dt.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "# ---------------- helpers ----------------\n",
    "def clean(s):\n",
    "    return re.sub(r\"\\s+\",\" \",str(s).replace(\"\\u00a0\",\" \")).strip() if s is not None else \"\"\n",
    "\n",
    "def pfloat(s):\n",
    "    if s is None or clean(s)==\"\" or clean(s) in {\"-\",\"–\",\"—\"}:\n",
    "        return None\n",
    "    raw = str(s)\n",
    "    if \",\" in raw and \".\" in raw:\n",
    "        raw = raw.replace(\".\", \"\").replace(\",\", \".\")\n",
    "    else:\n",
    "        raw = raw.replace(\",\", \"\")\n",
    "    raw = re.sub(r\"[^\\d\\.\\-]\", \"\", raw)\n",
    "    try:\n",
    "        return float(raw)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def parse_date(s):\n",
    "    s = clean(s)\n",
    "    for dayfirst in (False, True):\n",
    "        try:\n",
    "            return dtparse.parse(s, dayfirst=dayfirst, fuzzy=True)\n",
    "        except:\n",
    "            pass\n",
    "    return None\n",
    "\n",
    "def xnpv(rate, cashflows):\n",
    "    t0 = min(d for d,_ in cashflows)\n",
    "    days = 365.2425\n",
    "    return sum(amt/((1+rate)**((d-t0).days/days)) for d,amt in cashflows)\n",
    "\n",
    "def xirr(cashflows):\n",
    "    if not cashflows:\n",
    "        return None\n",
    "    lo, hi = -0.9999, 10.0\n",
    "    f_lo, f_hi = xnpv(lo, cashflows), xnpv(hi, cashflows)\n",
    "    tries = 0\n",
    "    while f_lo*f_hi > 0 and tries < 25:\n",
    "        hi *= 1.5\n",
    "        f_hi = xnpv(hi, cashflows); tries += 1\n",
    "        if not math.isfinite(f_hi):\n",
    "            break\n",
    "    if f_lo*f_hi > 0:\n",
    "        return None\n",
    "    for _ in range(120):\n",
    "        mid = (lo+hi)/2\n",
    "        f   = xnpv(mid, cashflows)\n",
    "        if abs(f) < 1e-6:\n",
    "            return mid\n",
    "        if f*f_lo > 0:\n",
    "            lo, f_lo = mid, f\n",
    "        else:\n",
    "            hi, f_hi = mid, f\n",
    "    return (lo+hi)/2\n",
    "\n",
    "def ks_pme(cashflows, index_df):\n",
    "    \"\"\"\n",
    "    Kaplan-Schoar PME: sum(CF_t * I_T/I_t) / sum(-Contr_t * I_T/I_t)\n",
    "    index_df precisa ter colunas: date (datetime) e index (nível acumulado)\n",
    "    \"\"\"\n",
    "    if index_df is None or index_df.empty:\n",
    "        return None\n",
    "    idx = index_df.sort_values(\"date\")\n",
    "    T   = idx[\"index\"].iloc[-1]\n",
    "\n",
    "    def level_on(d):\n",
    "        i = idx[idx[\"date\"] <= d]\n",
    "        if i.empty:\n",
    "            i = idx.iloc[:1]  # fallback: usa primeiro nível\n",
    "        return i[\"index\"].iloc[-1]\n",
    "\n",
    "    num = 0.0; den = 0.0\n",
    "    for d,amt in cashflows:\n",
    "        L = level_on(d)\n",
    "        adj = amt * (T / L)\n",
    "        if amt >= 0:\n",
    "            num += adj\n",
    "        else:\n",
    "            den += -adj\n",
    "    if den == 0:\n",
    "        return None\n",
    "    return num / den\n",
    "\n",
    "# --------------- CDI (série) ---------------\n",
    "def fetch_cdi_index():\n",
    "    \"\"\"\n",
    "    Usa API (MaisRetorno) para pegar CDI.\n",
    "    Se 'c' vier como taxa/variação diária, acumula para formar um índice base 100.\n",
    "    \"\"\"\n",
    "    url = \"https://api.maisretorno.com/v3/indexes/quotes/cdi\"\n",
    "    r = requests.get(url, timeout=30, headers={\"Accept\": \"application/json\"})\n",
    "    r.raise_for_status()\n",
    "    dados = r.json()\n",
    "\n",
    "    if isinstance(dados, dict) and \"quotes\" in dados:\n",
    "        df_q = pd.DataFrame(dados[\"quotes\"])\n",
    "    else:\n",
    "        df_q = pd.DataFrame(pd.DataFrame(dados)[\"quotes\"].tolist())\n",
    "\n",
    "    # campos esperados: 'd' (ms epoch), 'c' (valor)\n",
    "    df_q[\"date\"]  = pd.to_datetime(df_q[\"d\"], unit=\"ms\", errors=\"coerce\")\n",
    "    df_q[\"value\"] = pd.to_numeric(df_q[\"c\"], errors=\"coerce\")\n",
    "    df_q = df_q.dropna(subset=[\"date\",\"value\"]).sort_values(\"date\")\n",
    "\n",
    "    # Se parecer variação pequena, acumula; caso contrário, assume que já é nível\n",
    "    if df_q[\"value\"].median() < 5:\n",
    "        base = 100.0\n",
    "        levels = [base]\n",
    "        for v in df_q[\"value\"].tolist():\n",
    "            levels.append(levels[-1] * (1 + float(v)/100.0))\n",
    "        df_q[\"index\"] = levels[1:]\n",
    "    else:\n",
    "        df_q[\"index\"] = df_q[\"value\"]\n",
    "\n",
    "    return df_q[[\"date\",\"index\"]]\n",
    "\n",
    "# --------------- Scraper Playwright ---------------\n",
    "async def scrape_vehicle_financials():\n",
    "    \"\"\"\n",
    "    Abre o FUND_URL, entra no Vehicle e extrai a seção Financials.\n",
    "    Tenta DOM; se falhar, usa fallback por texto + regex.\n",
    "    Retorna DataFrame com colunas: date, spec, contr, distr, contr_adj, distr_adj, nav\n",
    "    \"\"\"\n",
    "    async with async_playwright() as p:\n",
    "        ctx = await p.chromium.launch_persistent_context(USER_DATA, headless=HEADLESS)\n",
    "        try:\n",
    "            page = ctx.pages[0] if ctx.pages else await ctx.new_page()\n",
    "            page.set_default_timeout(120_000)\n",
    "\n",
    "            await page.goto(FUND_URL, wait_until=\"domcontentloaded\", timeout=120_000)\n",
    "            try:\n",
    "                await page.wait_for_load_state(\"load\", timeout=60_000)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            # tenta clicar no card/linha do vehicle\n",
    "            try:\n",
    "                await page.get_by_text(\"ANGRA INFRA\", exact=False).first.click()\n",
    "            except:\n",
    "                pass  # pode já estar na página\n",
    "\n",
    "            # garante que carregou algo com cara de Financials\n",
    "            try:\n",
    "                await page.wait_for_function(\n",
    "                    \"document.body && /Vehicle\\\\s*Name:|Financials|Date\\\\s+Specification\\\\s+Contribution\\\\(f\\\\)/i.test(document.body.innerText)\",\n",
    "                    timeout=90_000\n",
    "                )\n",
    "            except:\n",
    "                raise RuntimeError(\"Não consegui abrir a página do Vehicle/Financials. Verifique login.\")\n",
    "\n",
    "            # rola até Financials\n",
    "            try:\n",
    "                loc = page.get_by_text(\"Financials\", exact=False).first\n",
    "                await loc.scroll_into_view_if_needed()\n",
    "                await page.wait_for_timeout(1200)\n",
    "            except:\n",
    "                for _ in range(6):\n",
    "                    await page.mouse.wheel(0, 2000)\n",
    "                    await page.wait_for_timeout(500)\n",
    "\n",
    "            # 1) tenta extrair via DOM\n",
    "            rows = []\n",
    "            try:\n",
    "                container = page.locator(\"xpath=//*[contains(., 'Date') and contains(., 'Net Asset Value')]\").last\n",
    "                table = container.locator(\"xpath=.//table[.//th[contains(.,'Date')]]\").first\n",
    "                if await table.count() == 0:\n",
    "                    grid = container.locator(\"xpath=.//*[contains(., 'Date')]/following::*\").first\n",
    "                    trs = grid.locator(\"tr\")\n",
    "                    if await trs.count() > 0:\n",
    "                        for i in range(await trs.count()):\n",
    "                            trow = trs.nth(i)\n",
    "                            cells = trow.locator(\"xpath=.//th|.//td\")\n",
    "                            cols = [clean(await cells.nth(j).inner_text()) for j in range(await cells.count())]\n",
    "                            rows.append(cols)\n",
    "                    else:\n",
    "                        divrows = grid.locator(\"xpath=.//*[self::div or self::li][descendant::*[contains(text(),'Jan') or contains(text(),'Feb') or contains(text(),'Mar') or contains(text(),'Dec') or contains(text(),', 20')]]\")\n",
    "                        n = await divrows.count()\n",
    "                        for i in range(n):\n",
    "                            txt = clean(await divrows.nth(i).inner_text())\n",
    "                            rows.append(re.split(r\"\\s{2,}\", txt))\n",
    "                else:\n",
    "                    tr = table.locator(\"xpath=.//tr\")\n",
    "                    n = await tr.count()\n",
    "                    for i in range(n):\n",
    "                        trow = tr.nth(i)\n",
    "                        cells = trow.locator(\"xpath=.//th|.//td\")\n",
    "                        cols = [clean(await cells.nth(j).inner_text()) for j in range(await cells.count())]\n",
    "                        rows.append(cols)\n",
    "            except:\n",
    "                rows = []\n",
    "\n",
    "            def shape_dom_rows(rows):\n",
    "                if not rows:\n",
    "                    return None\n",
    "                header_idx = None\n",
    "                for i, r in enumerate(rows):\n",
    "                    line = \" \".join(r).lower()\n",
    "                    if \"date\" in line and \"contribution\" in line and \"net asset value\" in line:\n",
    "                        header_idx = i; break\n",
    "                if header_idx is None:\n",
    "                    return None\n",
    "                data = rows[header_idx+1:]\n",
    "                out = []\n",
    "                for r in data:\n",
    "                    if len(r) < 7:\n",
    "                        continue\n",
    "                    d = parse_date(r[0])\n",
    "                    if not d:\n",
    "                        continue\n",
    "                    out.append({\n",
    "                        \"date\": d,\n",
    "                        \"spec\": clean(r[1]),\n",
    "                        \"contr\": pfloat(r[2]),\n",
    "                        \"distr\": pfloat(r[3]),\n",
    "                        \"contr_adj\": pfloat(r[4]),\n",
    "                        \"distr_adj\": pfloat(r[5]),\n",
    "                        \"nav\": pfloat(r[6]),\n",
    "                    })\n",
    "                return pd.DataFrame(out) if out else None\n",
    "\n",
    "            df_dom = shape_dom_rows(rows)\n",
    "\n",
    "            # 2) fallback texto+regex\n",
    "            if df_dom is None or df_dom.empty:\n",
    "                block_text = await page.evaluate(\"\"\"\n",
    "                    () => {\n",
    "                      const nodes = Array.from(document.querySelectorAll('*'))\n",
    "                        .filter(n => /Date\\\\s+Specification\\\\s+Contribution\\\\(f\\\\).*Net\\\\s+Asset\\\\s+Value/i.test(n.textContent || ''));\n",
    "                      if (nodes.length) return nodes[0].innerText;\n",
    "                      return document.body.innerText;\n",
    "                    }\n",
    "                \"\"\")\n",
    "            else:\n",
    "                block_text = None\n",
    "        finally:\n",
    "            await ctx.close()\n",
    "\n",
    "    if df_dom is not None and not df_dom.empty:\n",
    "        return df_dom\n",
    "\n",
    "    # --- regex fallback ---\n",
    "    header_rgx = re.compile(r\"Date\\s+Specification\\s+Contribution\\(f\\)\\s+Distribution\\(f\\)\\s+Adjusted\\s+Contr.*?Net\\s+Asset\\s+Value\", re.I)\n",
    "    m = header_rgx.search(block_text or \"\")\n",
    "    if not m:\n",
    "        raise RuntimeError(\"Não encontrei o cabeçalho da tabela de Financials (nem por DOM nem por texto).\")\n",
    "    block = (block_text or \"\")[m.end():]\n",
    "    cut = re.search(r\"(?:\\n|\\r)(?:Sub\\s+Total|Total)\\b\", block, flags=re.I)\n",
    "    if cut:\n",
    "        block = block[:cut.start()]\n",
    "\n",
    "    line_rgx = re.compile(\n",
    "        r\"(\\d{1,2}\\s+\\w{3},\\s+\\d{4})\\s+([A-Za-zÀ-ÿ ]+?)\\s+([\\-0-9\\.,]+)\\s+([\\-0-9\\.,]+)\\s+([\\-0-9\\.,]+)\\s+([\\-0-9\\.,]+)\\s+([\\-0-9\\.,]+)\",\n",
    "        re.I\n",
    "    )\n",
    "    out = []\n",
    "    for mm in line_rgx.finditer(block):\n",
    "        d = parse_date(mm.group(1))\n",
    "        if not d:\n",
    "            continue\n",
    "        out.append({\n",
    "            \"date\": d,\n",
    "            \"spec\": clean(mm.group(2)),\n",
    "            \"contr\": pfloat(mm.group(3)),\n",
    "            \"distr\": pfloat(mm.group(4)),\n",
    "            \"contr_adj\": pfloat(mm.group(5)),\n",
    "            \"distr_adj\": pfloat(mm.group(6)),\n",
    "            \"nav\": pfloat(mm.group(7)),\n",
    "        })\n",
    "    df = pd.DataFrame(out).dropna(subset=[\"date\"]).sort_values(\"date\").reset_index(drop=True)\n",
    "    if df.empty:\n",
    "        raise RuntimeError(\"Achei o bloco de Financials, mas não consegui ler nenhuma linha.\")\n",
    "    return df\n",
    "\n",
    "# --------------- cálculo das métricas + séries ---------------\n",
    "def compute_metrics_and_series(fin: pd.DataFrame, cdi_idx: pd.DataFrame | None):\n",
    "    fin = fin.sort_values(\"date\").reset_index(drop=True)\n",
    "\n",
    "    # métricas agregadas (as-of último registro)\n",
    "    paid_in       = fin[\"contr\"].fillna(0).sum()\n",
    "    distributions = fin[\"distr\"].fillna(0).sum()\n",
    "    nav_last      = fin[\"nav\"].dropna().iloc[-1] if fin[\"nav\"].notna().any() else 0.0\n",
    "\n",
    "    paid_in_a       = fin[\"contr_adj\"].fillna(0).sum()\n",
    "    distributions_a = fin[\"distr_adj\"].fillna(0).sum()\n",
    "\n",
    "    def div(a,b): return (a/b) if b not in (None,0) else None\n",
    "\n",
    "    agg = {\n",
    "        \"asof_date\": fin[\"date\"].iloc[-1],\n",
    "        \"paid_in\": paid_in,\n",
    "        \"distributions\": distributions,\n",
    "        \"NAV_last\": nav_last,\n",
    "        \"TVPI\": div(distributions + nav_last, paid_in),\n",
    "        \"DPI\":  div(distributions, paid_in),\n",
    "        \"RVPI\": div(nav_last, paid_in),\n",
    "        \"paid_in_adj\": paid_in_a,\n",
    "        \"distributions_adj\": distributions_a,\n",
    "        \"TVPI_adj\": div(distributions_a + nav_last, paid_in_a),\n",
    "        \"DPI_adj\":  div(distributions_a, paid_in_a),\n",
    "        \"RVPI_adj\": div(nav_last, paid_in_a),\n",
    "    }\n",
    "\n",
    "    # IRR (as-of)\n",
    "    cf = [(r.date, -(r.contr or 0.0)) for r in fin.itertuples()] + \\\n",
    "         [(r.date,  (r.distr or 0.0)) for r in fin.itertuples()]\n",
    "    if nav_last:\n",
    "        cf.append((fin[\"date\"].iloc[-1], nav_last))\n",
    "    agg[\"IRR\"] = xirr(cf)\n",
    "\n",
    "    cf_a = [(r.date, -(r.contr_adj or 0.0)) for r in fin.itertuples()] + \\\n",
    "           [(r.date,  (r.distr_adj or 0.0)) for r in fin.itertuples()]\n",
    "    if nav_last:\n",
    "        cf_a.append((fin[\"date\"].iloc[-1], nav_last))\n",
    "    agg[\"IRR_adj\"] = xirr(cf_a)\n",
    "\n",
    "    # Séries anuais (DPI/RVPI/TVPI por ano) – cumulativos até 31/12\n",
    "    years = sorted(set(d.year for d in fin[\"date\"]))\n",
    "    rows = []\n",
    "    for y in years:\n",
    "        cut = fin[fin[\"date\"] <= dt.datetime(y,12,31)]\n",
    "        if cut.empty:\n",
    "            continue\n",
    "        pi   = cut[\"contr\"].fillna(0).sum()\n",
    "        dist = cut[\"distr\"].fillna(0).sum()\n",
    "        navy = cut[\"nav\"].dropna().iloc[-1] if cut[\"nav\"].notna().any() else None\n",
    "        rows.append({\n",
    "            \"year\": y,\n",
    "            \"paid_in\": pi,\n",
    "            \"distributions\": dist,\n",
    "            \"NAV\": navy,\n",
    "            \"DPI\": div(dist, pi),\n",
    "            \"RVPI\": div(navy, pi) if navy is not None else None,\n",
    "            \"TVPI\": div((dist + (navy or 0)), pi),\n",
    "        })\n",
    "    ratios_by_year = pd.DataFrame(rows)\n",
    "\n",
    "    # IRR “as-of por ano”\n",
    "    irr_rows = []\n",
    "    for y in years:\n",
    "        cut = fin[fin[\"date\"] <= dt.datetime(y,12,31)]\n",
    "        if cut.empty:\n",
    "            continue\n",
    "        navy = cut[\"nav\"].dropna().iloc[-1] if cut[\"nav\"].notna().any() else 0.0\n",
    "        cf_y = [(r.date, -(r.contr or 0.0)) for r in cut.itertuples()] + \\\n",
    "               [(r.date,  (r.distr or 0.0)) for r in cut.itertuples()]\n",
    "        if navy:\n",
    "            cf_y.append((dt.datetime(y,12,31), navy))\n",
    "        irr_rows.append({\"year\": y, \"IRR_asof\": xirr(cf_y)})\n",
    "    irr_by_year = pd.DataFrame(irr_rows)\n",
    "\n",
    "    # PME (CDI)\n",
    "    pme_cdi_asof = None\n",
    "    pme_cdi_by_year = pd.DataFrame()\n",
    "    if cdi_idx is not None and not cdi_idx.empty:\n",
    "        pme_cdi_asof = ks_pme(cf, cdi_idx)\n",
    "        out = []\n",
    "        for y in years:\n",
    "            cut = fin[fin[\"date\"] <= dt.datetime(y,12,31)]\n",
    "            if cut.empty:\n",
    "                continue\n",
    "            navy = cut[\"nav\"].dropna().iloc[-1] if cut[\"nav\"].notna().any() else 0.0\n",
    "            cf_y = [(r.date, -(r.contr or 0.0)) for r in cut.itertuples()] + \\\n",
    "                   [(r.date,  (r.distr or 0.0)) for r in cut.itertuples()]\n",
    "            if navy:\n",
    "                cf_y.append((dt.datetime(y,12,31), navy))\n",
    "            out.append({\"year\": y, \"PME_CDI\": ks_pme(cf_y, cdi_idx)})\n",
    "        pme_cdi_by_year = pd.DataFrame(out)\n",
    "\n",
    "    agg[\"PME_CDI\"] = pme_cdi_asof\n",
    "    return pd.DataFrame([agg]), ratios_by_year, irr_by_year, pme_cdi_by_year\n",
    "\n",
    "# --------------- runner ---------------\n",
    "async def main():\n",
    "    fin = await scrape_vehicle_financials()\n",
    "    cdi_idx = fetch_cdi_index()\n",
    "\n",
    "    metrics_df, ratios_year_df, irr_year_df, pme_cdi_year_df = compute_metrics_and_series(fin, cdi_idx)\n",
    "\n",
    "    with pd.ExcelWriter(OUTPUT_XLSX, engine=\"openpyxl\", mode=\"w\") as xw:\n",
    "        fin.to_excel(xw, sheet_name=\"financials\", index=False)\n",
    "        metrics_df.to_excel(xw, sheet_name=\"metrics_asof\", index=False)\n",
    "        ratios_year_df.to_excel(xw, sheet_name=\"ratios_by_year\", index=False)\n",
    "        irr_year_df.to_excel(xw, sheet_name=\"irr_by_year\", index=False)\n",
    "        pme_cdi_year_df.to_excel(xw, sheet_name=\"pme_cdi_by_year\", index=False)\n",
    "        cdi_idx.to_excel(xw, sheet_name=\"cdi_index\", index=False)\n",
    "\n",
    "    print(\"✅ OK! Planilha salva em:\", OUTPUT_XLSX)\n",
    "    print(\"Linhas de Financials:\", len(fin))\n",
    "\n",
    "# No notebook:  await main()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dc39fd45-dcf7-456d-8b49-31fb7cb5203d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- PATCH: 2FA manual + sessão persistente e storageState ---\n",
    "\n",
    "import os, re, asyncio, datetime as dt\n",
    "from pathlib import Path\n",
    "from getpass import getpass\n",
    "import pandas as pd\n",
    "from playwright.async_api import async_playwright, TimeoutError as PWTimeout\n",
    "\n",
    "# Parâmetros (já usa seu perfil persistente)\n",
    "USER_DATA    = os.path.join(Path.home(), \".pw-angra\")\n",
    "FUND_URL     = \"https://pebay.info/backoffice/fund/angra-infra\"\n",
    "OUTPUT_DIR   = r\"C:\\Users\\otavi\\OneDrive\\Documentos\\Estudos_2025\\COINP\\PROJECOES\\BANCODEDADOS\\FIPS\"\n",
    "HEADLESS     = False\n",
    "STATE_JSON   = os.path.join(USER_DATA, \"pebay_state.json\")  # estado reutilizável\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "os.makedirs(USER_DATA, exist_ok=True)\n",
    "\n",
    "async def is_connected(page):\n",
    "    try:\n",
    "        return await page.evaluate(\n",
    "            \"() => !!(window.Meteor && Meteor.status && Meteor.status().connected)\"\n",
    "        )\n",
    "    except:\n",
    "        # fallback: testa presença de elementos do backoffice\n",
    "        try:\n",
    "            return await page.evaluate(\n",
    "                \"() => /backoffice/i.test(location.pathname)\"\n",
    "            )\n",
    "        except:\n",
    "            return False\n",
    "\n",
    "async def wait_manual_2fa(page, ctx, max_seconds=240):\n",
    "    \"\"\"\n",
    "    Mostra o browser para você fazer o 2FA; aguarda até autenticar ou estourar o tempo.\n",
    "    Ao autenticar, salva storageState para reuso.\n",
    "    \"\"\"\n",
    "    print(\"🔐 Aguarde/autentique o 2FA na janela aberta. Tenho até\", max_seconds, \"s.\")\n",
    "    deadline = dt.datetime.now() + dt.timedelta(seconds=max_seconds)\n",
    "\n",
    "    # pequenos hints de seletores de 2FA, caso apareçam\n",
    "    possible_2fa_selectors = [\n",
    "        'input[name*=\"code\"]', 'input[id*=\"code\"]', 'input[type=\"tel\"]',\n",
    "        'text=Two-Factor', 'text=Verificação em duas etapas', 'text=Authenticator'\n",
    "    ]\n",
    "\n",
    "    while dt.datetime.now() < deadline:\n",
    "        if await is_connected(page):\n",
    "            try:\n",
    "                await ctx.storage_state(path=STATE_JSON)\n",
    "            except Exception as e:\n",
    "                print(\"Aviso: não consegui salvar storageState:\", e)\n",
    "            print(\"✅ 2FA concluído. Sessão autenticada.\")\n",
    "            return True\n",
    "\n",
    "        # Se aparecer campo de código, dá foco (só ajuda visualmente)\n",
    "        try:\n",
    "            for sel in possible_2fa_selectors:\n",
    "                loc = page.locator(sel)\n",
    "                if await loc.count():\n",
    "                    try:\n",
    "                        await loc.first.focus()\n",
    "                        break\n",
    "                    except:\n",
    "                        pass\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        await asyncio.sleep(1.5)\n",
    "\n",
    "    raise RuntimeError(\"Tempo esgotado aguardando 2FA manual.\")\n",
    "\n",
    "async def open_context_and_login():\n",
    "    \"\"\"\n",
    "    Se existir STATE_JSON, tenta usá-lo; senão, abre contexto persistente e espera 2FA.\n",
    "    Retorna (ctx, page) autenticados.\n",
    "    \"\"\"\n",
    "    p = await async_playwright().start()\n",
    "\n",
    "    # Preferir contexto persistente para reaproveitar cookies e SSO\n",
    "    ctx = await p.chromium.launch_persistent_context(\n",
    "        USER_DATA,\n",
    "        headless=HEADLESS,\n",
    "        args=[\"--start-maximized\"],\n",
    "        no_viewport=True,\n",
    "        # slow_mo=50,  # opcional: mais “humano” para 2FA\n",
    "    )\n",
    "    page = ctx.pages[0] if ctx.pages else await ctx.new_page()\n",
    "\n",
    "    # Vai para o destino\n",
    "    await page.goto(FUND_URL, wait_until=\"domcontentloaded\", timeout=120_000)\n",
    "    try:\n",
    "        await page.wait_for_load_state(\"load\", timeout=60_000)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # Já está logado?\n",
    "    if await is_connected(page):\n",
    "        return p, ctx, page\n",
    "\n",
    "    # Caso não esteja, aguarda o 2FA manual\n",
    "    await wait_manual_2fa(page, ctx, max_seconds=240)\n",
    "\n",
    "    # Garante que estamos na página do veículo após login\n",
    "    if not re.search(r\"/fund/angra-infra\", page.url, re.I):\n",
    "        await page.goto(FUND_URL, wait_until=\"domcontentloaded\", timeout=120_000)\n",
    "        try:\n",
    "            await page.wait_for_load_state(\"load\", timeout=60_000)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    return p, ctx, page\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "32b44264-7852-41a0-a4ce-6fdb7a21fba7",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Não consegui abrir a página do Vehicle/Financials. Verifique login.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTargetClosedError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 171\u001b[0m, in \u001b[0;36mscrape_vehicle_financials\u001b[1;34m()\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 171\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m page\u001b[38;5;241m.\u001b[39mwait_for_function(\n\u001b[0;32m    172\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdocument.body && /Vehicle\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124ms*Name:|Financials|Date\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124ms+Specification\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124ms+Contribution\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124m(f\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124m)/i.test(document.body.innerText)\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    173\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m90_000\u001b[39m\n\u001b[0;32m    174\u001b[0m     )\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\playwright\\async_api\\_generated.py:11479\u001b[0m, in \u001b[0;36mPage.wait_for_function\u001b[1;34m(self, expression, arg, timeout, polling)\u001b[0m\n\u001b[0;32m  11424\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Page.wait_for_function\u001b[39;00m\n\u001b[0;32m  11425\u001b[0m \n\u001b[0;32m  11426\u001b[0m \u001b[38;5;124;03mReturns when the `expression` returns a truthy value. It resolves to a JSHandle of the truthy value.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  11475\u001b[0m \u001b[38;5;124;03mJSHandle\u001b[39;00m\n\u001b[0;32m  11476\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m  11478\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m mapping\u001b[38;5;241m.\u001b[39mfrom_impl(\n\u001b[1;32m> 11479\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_impl_obj\u001b[38;5;241m.\u001b[39mwait_for_function(\n\u001b[0;32m  11480\u001b[0m         expression\u001b[38;5;241m=\u001b[39mexpression,\n\u001b[0;32m  11481\u001b[0m         arg\u001b[38;5;241m=\u001b[39mmapping\u001b[38;5;241m.\u001b[39mto_impl(arg),\n\u001b[0;32m  11482\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m  11483\u001b[0m         polling\u001b[38;5;241m=\u001b[39mpolling,\n\u001b[0;32m  11484\u001b[0m     )\n\u001b[0;32m  11485\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\playwright\\_impl\\_page.py:1111\u001b[0m, in \u001b[0;36mPage.wait_for_function\u001b[1;34m(self, expression, arg, timeout, polling)\u001b[0m\n\u001b[0;32m   1104\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwait_for_function\u001b[39m(\n\u001b[0;32m   1105\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1106\u001b[0m     expression: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1109\u001b[0m     polling: Union[\u001b[38;5;28mfloat\u001b[39m, Literal[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraf\u001b[39m\u001b[38;5;124m\"\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1110\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m JSHandle:\n\u001b[1;32m-> 1111\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_main_frame\u001b[38;5;241m.\u001b[39mwait_for_function(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mlocals_to_params(\u001b[38;5;28mlocals\u001b[39m()))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\playwright\\_impl\\_frame.py:860\u001b[0m, in \u001b[0;36mFrame.wait_for_function\u001b[1;34m(self, expression, arg, timeout, polling)\u001b[0m\n\u001b[0;32m    858\u001b[0m     params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpollingInterval\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m polling\n\u001b[0;32m    859\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m from_channel(\n\u001b[1;32m--> 860\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_channel\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwaitForFunction\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout, params)\n\u001b[0;32m    861\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\playwright\\_impl\\_connection.py:69\u001b[0m, in \u001b[0;36mChannel.send\u001b[1;34m(self, method, timeout_calculator, params, is_internal, title)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msend\u001b[39m(\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m     63\u001b[0m     method: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     67\u001b[0m     title: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     68\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m---> 69\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection\u001b[38;5;241m.\u001b[39mwrap_api_call(\n\u001b[0;32m     70\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inner_send(method, timeout_calculator, params, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m     71\u001b[0m         is_internal,\n\u001b[0;32m     72\u001b[0m         title,\n\u001b[0;32m     73\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\playwright\\_impl\\_connection.py:558\u001b[0m, in \u001b[0;36mConnection.wrap_api_call\u001b[1;34m(self, cb, is_internal, title)\u001b[0m\n\u001b[0;32m    557\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[1;32m--> 558\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m rewrite_error(error, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparsed_st[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mapiName\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merror\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    559\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[1;31mTargetClosedError\u001b[0m: Page.wait_for_function: Target page, context or browser has been closed",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m main()\n",
      "Cell \u001b[1;32mIn[19], line 401\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    400\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmain\u001b[39m():\n\u001b[1;32m--> 401\u001b[0m     fin \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m scrape_vehicle_financials()\n\u001b[0;32m    402\u001b[0m     cdi_idx \u001b[38;5;241m=\u001b[39m fetch_cdi_index()\n\u001b[0;32m    404\u001b[0m     metrics_df, ratios_year_df, irr_year_df, pme_cdi_year_df \u001b[38;5;241m=\u001b[39m compute_metrics_and_series(fin, cdi_idx)\n",
      "Cell \u001b[1;32mIn[19], line 176\u001b[0m, in \u001b[0;36mscrape_vehicle_financials\u001b[1;34m()\u001b[0m\n\u001b[0;32m    171\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m page\u001b[38;5;241m.\u001b[39mwait_for_function(\n\u001b[0;32m    172\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdocument.body && /Vehicle\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124ms*Name:|Financials|Date\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124ms+Specification\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124ms+Contribution\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124m(f\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124m)/i.test(document.body.innerText)\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    173\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m90_000\u001b[39m\n\u001b[0;32m    174\u001b[0m     )\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m--> 176\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNão consegui abrir a página do Vehicle/Financials. Verifique login.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    178\u001b[0m \u001b[38;5;66;03m# rola até Financials\u001b[39;00m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Não consegui abrir a página do Vehicle/Financials. Verifique login."
     ]
    }
   ],
   "source": [
    "await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc7c2da-bd94-4f0e-91ac-c9911619a4c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
