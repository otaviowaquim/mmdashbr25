{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f9a944-8859-4a5c-a7de-f9cafb749bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import logging\n",
    "import warnings\n",
    "from datetime import datetime, timedelta\n",
    "from datetime import datetime as _dt\n",
    "import unicodedata\n",
    "from pathlib import Path\n",
    "\n",
    "import dash\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import requests\n",
    "from dash import dcc, html\n",
    "from dash.dependencies import Input, Output\n",
    "from dotenv import load_dotenv\n",
    "from sklearn.decomposition import PCA\n",
    "from plotly.subplots import make_subplots\n",
    "from plotly.figure_factory import create_dendrogram\n",
    "from scipy.cluster import hierarchy as sch\n",
    "from scipy.spatial import distance as ssd\n",
    "# opcional: plotly.express se você usa px em callbacks\n",
    "import plotly.express as px  # noqa\n",
    "\n",
    "load_dotenv()\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# LOGGING (Cloud Run envia stdout/stderr para Cloud Logging)\n",
    "# ------------------------------------------------------------------------------\n",
    "logging.basicConfig(\n",
    "    level=os.getenv(\"LOG_LEVEL\", \"INFO\"),\n",
    "    format=\"%(asctime)s %(levelname)s %(message)s\",\n",
    ")\n",
    "log = logging.getLogger(\"app\")\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# PARÂMETROS GERAIS\n",
    "# ------------------------------------------------------------------------------\n",
    "START_FILTER = pd.Timestamp(\"2021-06-30\", tz=None)\n",
    "WINDOW       = 252\n",
    "MINP         = 126\n",
    "ROLL_MM      = 5\n",
    "CLIP_RET     = 0.20\n",
    "TRIM_Q       = 0.10\n",
    "SCALE_FIX    = 10\n",
    "\n",
    "# Outliers Sharpe\n",
    "SH_LOW_Q     = 0.01\n",
    "SH_HIGH_Q    = 0.01\n",
    "MAD_K        = 6\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# REQUESTS SESSION COM RETRIES (robusto em Cloud Run)\n",
    "# ------------------------------------------------------------------------------\n",
    "from requests.adapters import HTTPAdapter\n",
    "from urllib3.util.retry import Retry\n",
    "\n",
    "def _build_session():\n",
    "    retry = Retry(\n",
    "        total=3,\n",
    "        connect=3,\n",
    "        read=3,\n",
    "        backoff_factor=0.5,\n",
    "        status_forcelist=[429, 500, 502, 503, 504],\n",
    "        allowed_methods=frozenset([\"GET\"]),\n",
    "        raise_on_status=False,\n",
    "    )\n",
    "    s = requests.Session()\n",
    "    s.headers.update({\"User-Agent\": \"fi-mm-dash/1.0\"})\n",
    "    s.mount(\"https://\", HTTPAdapter(max_retries=retry))\n",
    "    s.mount(\"http://\",  HTTPAdapter(max_retries=retry))\n",
    "    return s\n",
    "\n",
    "HTTP = _build_session()\n",
    "OFFLINE = os.getenv(\"OFFLINE\", \"0\") == \"1\"  # força modo offline se quiser\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# I/O HELPERS (seguros para Cloud Run; suportam local e GCS)\n",
    "# ------------------------------------------------------------------------------\n",
    "def _is_gcs_path(path: str) -> bool:\n",
    "    return isinstance(path, str) and path.startswith(\"gs://\")\n",
    "\n",
    "def _read_parquet_safe(path: str, empty_cols=None):\n",
    "    \"\"\"\n",
    "    Tenta ler parquet de:\n",
    "      - GCS (se gcsfs disponível e path = gs://...)\n",
    "      - local (image/container)\n",
    "    Retorna DataFrame vazio em caso de erro, sem quebrar o start.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if not path:\n",
    "            raise FileNotFoundError(\"caminho vazio\")\n",
    "\n",
    "        if _is_gcs_path(path):\n",
    "            try:\n",
    "                import gcsfs  # noqa: F401\n",
    "            except Exception as e:\n",
    "                log.warning(\"gcsfs não disponível para %s: %s\", path, e)\n",
    "                return pd.DataFrame(columns=empty_cols or [])\n",
    "\n",
    "        if _is_gcs_path(path) or Path(path).exists():\n",
    "            return pd.read_parquet(path)\n",
    "        else:\n",
    "            log.warning(\"Parquet não encontrado: %s\", path)\n",
    "    except Exception as e:\n",
    "        log.warning(\"Falha lendo parquet %s: %s\", path, e)\n",
    "    return pd.DataFrame(columns=empty_cols or [])\n",
    "\n",
    "def _read_excel_safe(path: str, parse_dates=None, index_col=None, sheet_name=0):\n",
    "    \"\"\"\n",
    "    Lê Excel (local/GCS) de forma segura.\n",
    "    - Usa gcsfs se for gs://\n",
    "    - Tenta engine default; se falhar, retorna DF vazio\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if not path:\n",
    "            raise FileNotFoundError(\"caminho vazio\")\n",
    "        if _is_gcs_path(path):\n",
    "            try:\n",
    "                import gcsfs  # noqa: F401\n",
    "            except Exception as e:\n",
    "                log.warning(\"gcsfs não disponível para %s: %s\", path, e)\n",
    "                return pd.DataFrame()\n",
    "        if _is_gcs_path(path) or Path(path).exists():\n",
    "            return pd.read_excel(path, parse_dates=parse_dates, sheet_name=sheet_name)\n",
    "        else:\n",
    "            log.warning(\"Excel não encontrado: %s\", path)\n",
    "    except Exception as e:\n",
    "        log.warning(\"Falha lendo excel %s: %s\", path, e)\n",
    "    return pd.DataFrame()\n",
    "\n",
    "def _load_index_series(url: str, name: str, timeout=8) -> pd.Series:\n",
    "    \"\"\"Carrega série de índice (CDI/IHFA) com retries e fallback a série vazia.\"\"\"\n",
    "    if OFFLINE:\n",
    "        log.info(\"OFFLINE=1 → pulando fetch de %s\", name)\n",
    "        return pd.Series(dtype=\"float64\")\n",
    "    try:\n",
    "        r = HTTP.get(url, timeout=timeout)\n",
    "        if r.status_code != 200:\n",
    "            log.warning(\"%s HTTP %s em %s\", name, r.status_code, url)\n",
    "            return pd.Series(dtype=\"float64\")\n",
    "        dados = r.json()\n",
    "        if isinstance(dados, dict) and \"quotes\" in dados:\n",
    "            df_q = pd.DataFrame(dados[\"quotes\"])\n",
    "        else:\n",
    "            df_q = pd.DataFrame(pd.DataFrame(dados)[\"quotes\"].tolist())\n",
    "        # datas em UTC → tira tz pra ficar alinhado com pandas naive\n",
    "        df_q[\"date\"]  = pd.to_datetime(df_q[\"d\"], unit=\"ms\", utc=True).dt.tz_localize(None)\n",
    "        df_q[\"value\"] = pd.to_numeric(df_q[\"c\"], errors=\"coerce\")\n",
    "        s = df_q.set_index(\"date\")[\"value\"].sort_index().dropna()\n",
    "        return s\n",
    "    except Exception as e:\n",
    "        log.warning(\"%s indisponível: %s\", name, e)\n",
    "        return pd.Series(dtype=\"float64\")\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# SÉRIES DE PREÇO E MAPPING (paths via env; default para diretório 'data/')\n",
    "# ------------------------------------------------------------------------------\n",
    "DFP_PATH      = os.getenv(\"DFP_PARQUET\",      \"data/df_p.parquet\")\n",
    "MAPPING_PATH  = os.getenv(\"MAPPING_PARQUET\",  \"data/mapping.parquet\")\n",
    "ATU_PATH      = os.getenv(\"ATUARIAL_XLSX\",    \"data/serie_historica_atuarial.xlsx\")\n",
    "\n",
    "df_p = _read_parquet_safe(DFP_PATH)\n",
    "if not isinstance(df_p.index, pd.DatetimeIndex):\n",
    "    # converte índice pra datetime; se falhar, substitui por índice vazio\n",
    "    try:\n",
    "        df_p.index = pd.to_datetime(df_p.index, utc=True).tz_localize(None)\n",
    "    except Exception:\n",
    "        df_p = pd.DataFrame(index=pd.to_datetime([]))\n",
    "\n",
    "mapping_df = _read_parquet_safe(MAPPING_PATH, empty_cols=[\"Ativo\", \"Nome\"])\n",
    "mapping = (\n",
    "    dict(zip(mapping_df.get(\"Ativo\", []), mapping_df.get(\"Nome\", [])))\n",
    "    if not mapping_df.empty else {}\n",
    ")\n",
    "\n",
    "# lista base de fundos (se não houver mapping, usa todas as colunas disponíveis)\n",
    "funds = [c for c in df_p.columns if c in mapping] if mapping else list(df_p.columns)\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# BENCHMARKS (CDI/IHFA com fallback) + Meta Atuarial (planilha)\n",
    "# ------------------------------------------------------------------------------\n",
    "cdi_idx  = _load_index_series(\"https://api.maisretorno.com/v3/indexes/quotes/cdi\",  \"CDI\")\n",
    "ihfa_idx = _load_index_series(\"https://api.maisretorno.com/v3/indexes/quotes/ihfa\", \"IHFA\")\n",
    "\n",
    "df_atu = _read_excel_safe(ATU_PATH, parse_dates=[\"Data\"])\n",
    "if not df_atu.empty and \"Data\" in df_atu.columns:\n",
    "    try:\n",
    "        df_atu = df_atu.set_index(pd.to_datetime(df_atu[\"Data\"], utc=True).dt.tz_localize(None)).sort_index()\n",
    "        atu_series = pd.to_numeric(df_atu.get(\"Cota\", pd.Series(dtype=\"float64\")), errors=\"coerce\").dropna()\n",
    "        atu_series.index.name = \"Data\"\n",
    "    except Exception as e:\n",
    "        log.warning(\"Falha ao processar Meta Atuarial: %s\", e)\n",
    "        atu_series = pd.Series(dtype=\"float64\")\n",
    "else:\n",
    "    log.warning(\"Meta Atuarial indisponível ou sem coluna 'Data'\")\n",
    "    atu_series = pd.Series(dtype=\"float64\")\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# CÁLCULOS GLOBAIS (sem filtros)\n",
    "# ------------------------------------------------------------------------------\n",
    "# Retornos diários dos fundos\n",
    "df_ret_full = df_p.pct_change(fill_method=None) if not df_p.empty else pd.DataFrame(index=pd.to_datetime([]))\n",
    "\n",
    "# CDI diário reindexado ao calendário dos fundos\n",
    "if not cdi_idx.empty and not df_ret_full.empty:\n",
    "    cdi_daily_idx = cdi_idx.reindex(df_ret_full.index, method=\"ffill\")\n",
    "    cdi_ret_daily = cdi_daily_idx.pct_change().fillna(0)\n",
    "else:\n",
    "    cdi_ret_daily = pd.Series(0.0, index=df_ret_full.index)\n",
    "\n",
    "# Vol anualizada em %\n",
    "if not df_ret_full.empty:\n",
    "    df_vol_full = (\n",
    "        df_ret_full\n",
    "        .rolling(WINDOW, min_periods=MINP)\n",
    "        .std()\n",
    "        .replace(0, pd.NA)\n",
    "        * (WINDOW ** 0.5) * 100\n",
    "    )\n",
    "else:\n",
    "    df_vol_full = pd.DataFrame(index=pd.to_datetime([]))\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# MORTALIDADE — caminho via env; funciona com gs:// ou local (Cloud Run-friendly)\n",
    "# ------------------------------------------------------------------------------\n",
    "# ------------------------------------------------------------------------------\n",
    "# MORTALIDADE — caminho via env; funciona com gs:// ou local (Cloud Run-friendly)\n",
    "# ------------------------------------------------------------------------------\n",
    "MORT_PATH = os.getenv(\"MORTALIDADE_XLSX\", \"data/inicio_fim.xlsx\")\n",
    "\n",
    "def _strip_accents(s):\n",
    "    return \"\".join(ch for ch in unicodedata.normalize(\"NFKD\", str(s)) if not unicodedata.combining(ch))\n",
    "\n",
    "def _norm(s):\n",
    "    return _strip_accents(s).strip().lower()\n",
    "\n",
    "def _pick_col(df, *aliases):\n",
    "    norm = {_norm(c): c for c in df.columns}\n",
    "    for a in aliases:\n",
    "        k = _norm(a)\n",
    "        if k in norm:\n",
    "            return norm[k]\n",
    "    for a in aliases:\n",
    "        k = _norm(a)\n",
    "        for nk, orig in norm.items():\n",
    "            if nk.startswith(k):\n",
    "                return orig\n",
    "    raise KeyError(f\"Não achei {aliases} em {MORT_PATH}\")\n",
    "\n",
    "def _digits(x):\n",
    "    return re.sub(r\"\\D\", \"\", \"\" if x is None else str(x))\n",
    "\n",
    "def _parse_excel_date(x):\n",
    "    if x is None or (isinstance(x, float) and np.isnan(x)) or (isinstance(x, str) and x.strip() in {\"\", \"-\", \"nan\", \"NaT\", \"None\"}):\n",
    "        return pd.NaT\n",
    "    if isinstance(x, (pd.Timestamp, _dt, np.datetime64)):\n",
    "        return pd.to_datetime(x, errors=\"coerce\")\n",
    "    dt = pd.to_datetime(str(x).strip(), dayfirst=True, errors=\"coerce\")\n",
    "    if pd.notna(dt):\n",
    "        return dt\n",
    "    num = pd.to_numeric(str(x).strip(), errors=\"coerce\")\n",
    "    if pd.notna(num):\n",
    "        base = pd.Timestamp(\"1899-12-30\")\n",
    "        return base + pd.to_timedelta(int(num), unit=\"D\")\n",
    "    return pd.NaT\n",
    "\n",
    "# --- leitura segura da planilha de mortalidade (local/gs://) ---\n",
    "_raw = _read_excel_safe(MORT_PATH)\n",
    "\n",
    "if _raw.empty or _raw.columns.empty:\n",
    "    log.warning(\"Planilha de mortalidade vazia/ausente: %s\", MORT_PATH)\n",
    "    df_life_all = pd.DataFrame(columns=[\"Codigo\", \"CodigoFinal\", \"Nome\", \"DataInicio\", \"DataFim\"])\n",
    "    MORT_MIN = pd.Timestamp(\"2000-01-01\")\n",
    "    MORT_MAX = pd.Timestamp.today().normalize()\n",
    "else:\n",
    "    def _safe_pick(df, *aliases, required=False):\n",
    "        try:\n",
    "            return _pick_col(df, *aliases)\n",
    "        except KeyError:\n",
    "            if required:\n",
    "                raise\n",
    "            return None\n",
    "\n",
    "    col_codigo = _safe_pick(_raw, \"Código\", \"Codigo\", required=True)\n",
    "    col_fim    = _safe_pick(_raw, \"Data Fim\", \"Fim\", required=True)\n",
    "    col_ini    = _safe_pick(_raw, \"Data Início\", \"Data Inicio\", \"Inicio\", required=False)\n",
    "\n",
    "    col_ativo = None\n",
    "    for c in _raw.columns:\n",
    "        if _norm(c).startswith(\"ativo\"):\n",
    "            col_ativo = c\n",
    "            break\n",
    "\n",
    "    rename_map = {col_codigo: \"Codigo\", col_fim: \"DataFim\"}\n",
    "    if col_ini is not None:\n",
    "        rename_map[col_ini] = \"DataInicio\"\n",
    "    if col_ativo is not None:\n",
    "        rename_map[col_ativo] = \"Ativo\"\n",
    "\n",
    "    df_life_all = _raw.rename(columns=rename_map).copy()\n",
    "\n",
    "    for needed in [\"Codigo\", \"DataFim\", \"DataInicio\", \"Ativo\", \"Nome\"]:\n",
    "        if needed not in df_life_all.columns:\n",
    "            df_life_all[needed] = pd.NA\n",
    "\n",
    "    df_life_all[\"Codigo\"] = df_life_all[\"Codigo\"].apply(_digits)\n",
    "    df_life_all[\"Ativo\"]  = df_life_all[\"Ativo\"].apply(_digits)\n",
    "\n",
    "    df_life_all[\"CodigoFinal\"] = np.where(\n",
    "        df_life_all[\"Codigo\"].astype(str) != \"\", df_life_all[\"Codigo\"], df_life_all[\"Ativo\"]\n",
    "    )\n",
    "\n",
    "    df_life_all[\"DataInicio\"] = df_life_all[\"DataInicio\"].apply(_parse_excel_date)\n",
    "    df_life_all[\"DataFim\"]    = df_life_all[\"DataFim\"].apply(_parse_excel_date)\n",
    "\n",
    "    _dates_for_minmax = []\n",
    "    if df_life_all[\"DataInicio\"].notna().any():\n",
    "        _dates_for_minmax.append(df_life_all[\"DataInicio\"].dropna())\n",
    "    if df_life_all[\"DataFim\"].notna().any():\n",
    "        _dates_for_minmax.append(df_life_all[\"DataFim\"].dropna())\n",
    "\n",
    "    if _dates_for_minmax:\n",
    "        _all_dates = pd.concat(_dates_for_minmax, ignore_index=True)\n",
    "        MORT_MIN = _all_dates.min().normalize()\n",
    "        MORT_MAX = _all_dates.max().normalize()\n",
    "    else:\n",
    "        MORT_MIN = pd.Timestamp(\"2000-01-01\")\n",
    "        MORT_MAX = pd.Timestamp.today().normalize()\n",
    "\n",
    "# (opcional) df_deaths se você usa em algum lugar\n",
    "df_deaths = df_life_all[\n",
    "    (df_life_all.get(\"CodigoFinal\", \"\").astype(str) != \"\") & df_life_all[\"DataFim\"].notna()\n",
    "].copy()\n",
    "if not df_deaths.empty:\n",
    "    df_deaths[\"Ano\"] = df_deaths[\"DataFim\"].dt.year.astype(\"Int64\")\n",
    "\n",
    "# ======================\n",
    "# Conjuntos de códigos por estilo (Macro / Long&Short)\n",
    "# ======================\n",
    "macro_codes = [\n",
    "    \"532673\",\"465501\",\"541427\",\"581194\",\"348341\",\"285560\",\n",
    "    \"396052\",\"227552\",\"323683\",\"469025\",\"419011\",\"320153\",\n",
    "    \"417890\",\"413259\",\"443808\"\n",
    "]\n",
    "ls_codes = [\"221260\",\"573019\",\"456748\",\"541133\",\"342092\"]\n",
    "codes    = macro_codes + ls_codes\n",
    "\n",
    "macro_cols   = [c for c in df_ret_full.columns if any(c.startswith(code) for code in macro_codes)]\n",
    "ls_cols      = [c for c in df_ret_full.columns if any(c.startswith(code) for code in ls_codes)]\n",
    "macro_labels = [mapping.get(c, c) for c in macro_cols]\n",
    "ls_labels    = [mapping.get(c, c) for c in ls_cols]\n",
    "\n",
    "fund_codes   = [c for c in df_ret_full.columns if any(c.startswith(code) for code in codes)]\n",
    "fund_options = [{\"label\": mapping.get(c, c), \"value\": c} for c in fund_codes]\n",
    "\n",
    "# ======================\n",
    "# mapping_all.parquet — leitura segura (local/GCS) + normalizações resilientes\n",
    "# ======================\n",
    "DF_ALL_PATH = os.getenv(\"MAPPING_ALL_PARQUET\", \"data/mapping_all.parquet\")\n",
    "_EXPECTED_COLS = [\n",
    "    \"CNPJ\",\"Gestora|\",\"Patrimônio|||em milhares\",\"Média de|Cotistas|1 mês|em unidades\",\n",
    "    \"Data do|Início da Série\",\"Comp carteira|3m Antes Ult|em %|Ihfa\",\n",
    "    \"Multigestor\",\"Fundo|exclusivo\",\"Forma de|condomínio\",\"Investimento|no Exterior\",\n",
    "    \"Restrito\",\"Ativo\"\n",
    "]\n",
    "df_all = _read_parquet_safe(DF_ALL_PATH, empty_cols=_EXPECTED_COLS)\n",
    "if df_all.empty:\n",
    "    log.warning(\"mapping_all.parquet vazio/ausente em %s — filtros MEG terão universo reduzido.\", DF_ALL_PATH)\n",
    "\n",
    "for col in _EXPECTED_COLS:\n",
    "    if col not in df_all.columns:\n",
    "        df_all[col] = pd.NA\n",
    "\n",
    "# Normalizações (sem KeyError mesmo se col faltar)\n",
    "df_all[\"CNPJ\"] = (\n",
    "    df_all.get(\"CNPJ\", pd.Series(dtype=str))\n",
    "          .astype(str)\n",
    "          .str.replace(r\"\\D\", \"\", regex=True)\n",
    "          .str.zfill(14)\n",
    ")\n",
    "df_all[\"Gestora|\"] = df_all.get(\"Gestora|\", \"\").astype(str).str.strip()\n",
    "df_all[\"Patrimônio|||em milhares\"] = pd.to_numeric(\n",
    "    df_all.get(\"Patrimônio|||em milhares\", pd.Series(dtype=\"float64\")), errors=\"coerce\"\n",
    ")\n",
    "df_all[\"Média de|Cotistas|1 mês|em unidades\"] = pd.to_numeric(\n",
    "    df_all.get(\"Média de|Cotistas|1 mês|em unidades\", pd.Series(dtype=\"float64\")), errors=\"coerce\"\n",
    ")\n",
    "df_all[\"Data do|Início da Série\"] = pd.to_datetime(\n",
    "    df_all.get(\"Data do|Início da Série\", pd.Series(dtype=\"datetime64[ns]\")), errors=\"coerce\"\n",
    ")\n",
    "df_all[\"Comp carteira|3m Antes Ult|em %|Ihfa\"] = pd.to_numeric(\n",
    "    df_all.get(\"Comp carteira|3m Antes Ult|em %|Ihfa\", pd.Series(dtype=\"float64\")), errors=\"coerce\"\n",
    ")\n",
    "df_all[\"Multigestor\"]            = df_all.get(\"Multigestor\", \"\").astype(str)\n",
    "df_all[\"Fundo|exclusivo\"]        = df_all.get(\"Fundo|exclusivo\", \"\").astype(str)\n",
    "df_all[\"Forma de|condomínio\"]    = df_all.get(\"Forma de|condomínio\", \"\").astype(str)\n",
    "df_all[\"Investimento|no Exterior\"]= df_all.get(\"Investimento|no Exterior\", \"\").astype(str)\n",
    "df_all[\"Restrito\"]               = df_all.get(\"Restrito\", \"\").astype(str)\n",
    "df_all[\"Ativo\"]                  = df_all.get(\"Ativo\", \"\").astype(str).str.replace(r\"\\D\", \"\", regex=True)\n",
    "\n",
    "# IHFA flag\n",
    "has_ihfa_mask = df_all[\"Comp carteira|3m Antes Ult|em %|Ihfa\"].notna()\n",
    "gestoras_com_ihfa = df_all.loc[has_ihfa_mask, \"Gestora|\"].dropna().unique()\n",
    "df_all[\"Gestora com histórico IHFA\"] = df_all[\"Gestora|\"].apply(\n",
    "    lambda g: \"SIM\" if g in set(gestoras_com_ihfa) else \"NÃO\"\n",
    ")\n",
    "\n",
    "# ======================\n",
    "# Parâmetros de atuação e janela fixa documentais (mantidos)\n",
    "# ======================\n",
    "BASE_ATUACAO = pd.Timestamp(\"2025-06-30\")\n",
    "ANOS_ATUACAO_MIN = 4\n",
    "data_corte = BASE_ATUACAO - pd.DateOffset(years=ANOS_ATUACAO_MIN)  # 2021-06-30\n",
    "\n",
    "WINDOW48_START = pd.Timestamp(\"2021-06-30\")\n",
    "WINDOW48_END   = pd.Timestamp(\"2025-06-30\")\n",
    "REBAL_DATES    = pd.to_datetime([\n",
    "    \"2021-06-30\", \"2022-06-30\", \"2023-06-30\", \"2024-06-30\", \"2025-06-30\"\n",
    "])\n",
    "\n",
    "# ======================\n",
    "# Filtros MEG (sem KeyError) + df_pl robusto\n",
    "# ======================\n",
    "filter_funcs = {\n",
    "    'patrimonio': lambda d: pd.to_numeric(d.get('Patrimônio|||em milhares'), errors='coerce') > 300_000,\n",
    "    'atuacao':     lambda d: pd.to_datetime(d.get('Data do|Início da Série'), errors='coerce') <= data_corte,\n",
    "    'cotistas':    lambda d: pd.to_numeric(d.get('Média de|Cotistas|1 mês|em unidades'), errors='coerce') > 100,\n",
    "    'multigestor': lambda d: ~d.get('Multigestor', pd.Series(\"\", index=d.index)).isin(['Multigestor', 'Espelho']),\n",
    "    'exclusivo':   lambda d: d.get('Fundo|exclusivo', pd.Series(\"\", index=d.index)) != 'Sim',\n",
    "    'condominio':  lambda d: d.get('Forma de|condomínio', pd.Series(\"\", index=d.index)) != 'Fechado',\n",
    "    'exterior':    lambda d: ~d.get('Investimento|no Exterior', pd.Series(\"\", index=d.index)).isin(['', 'Até 100%']),\n",
    "    'restrito':    lambda d: d.get('Restrito', pd.Series(\"\", index=d.index)) != 'Sim',\n",
    "    'ihfa':        lambda d: d.get('Gestora com histórico IHFA', pd.Series(\"\", index=d.index)) == 'SIM',\n",
    "}\n",
    "\n",
    "if \"Ativo\" in df_all.columns:\n",
    "    df_pl = pd.to_numeric(df_all.set_index(\"Ativo\").get(\"Patrimônio|||em milhares\"), errors=\"coerce\").fillna(0.0) * 1000.0\n",
    "else:\n",
    "    df_pl = pd.Series(dtype=\"float64\")\n",
    "\n",
    "\n",
    "# ======================\n",
    "# FUNÇÕES AUXILIARES\n",
    "# ======================\n",
    "def trim_mean_series(row, q=TRIM_Q):\n",
    "    vals = row.dropna().sort_values()\n",
    "    n = len(vals)\n",
    "    if n == 0:\n",
    "        return np.nan\n",
    "    k = int(n * q)\n",
    "    if 2 * k >= n:\n",
    "        return vals.mean()\n",
    "    return vals.iloc[k:n-k].mean()\n",
    "\n",
    "def robust_cross_section_mean(df_values):\n",
    "    clipped = df_values.clip(lower=-CLIP_RET, upper=CLIP_RET)\n",
    "    return clipped.apply(trim_mean_series, axis=1)\n",
    "\n",
    "\n",
    "def get_allowed_activos_at(ref_date: pd.Timestamp, selected_filters):\n",
    "    \"\"\"\n",
    "    Aplica os filtros do MEG NA DATA DE REBALANCE (ref_date).\n",
    "    Somente a condição de 'atuacao' muda com a data (4 anos antes).\n",
    "    Retorna apenas códigos existentes em df_p (com séries).\n",
    "    \"\"\"\n",
    "    d = df_all.copy()\n",
    "    selected_filters = selected_filters or []\n",
    "\n",
    "    for f in selected_filters:\n",
    "        if f == 'patrimonio':\n",
    "            d = d[d['Patrimônio|||em milhares'] > 300_000]\n",
    "        elif f == 'atuacao':\n",
    "            cutoff = ref_date - pd.DateOffset(years=ANOS_ATUACAO_MIN)\n",
    "            d = d[d['Data do|Início da Série'] <= cutoff]\n",
    "        elif f == 'cotistas':\n",
    "            d = d[d['Média de|Cotistas|1 mês|em unidades'] > 100]\n",
    "        elif f == 'multigestor':\n",
    "            d = d[~d['Multigestor'].isin(['Multigestor', 'Espelho'])]\n",
    "        elif f == 'exclusivo':\n",
    "            d = d[d['Fundo|exclusivo'] != 'Sim']\n",
    "        elif f == 'condominio':\n",
    "            d = d[d['Forma de|condomínio'] != 'Fechado']\n",
    "        elif f == 'exterior':\n",
    "            d = d[~d['Investimento|no Exterior'].isin(['', 'Até 100%'])]\n",
    "        elif f == 'restrito':\n",
    "            d = d[d['Restrito'] != 'Sim']\n",
    "        elif f == 'ihfa':\n",
    "            d = d[d['Gestora com histórico IHFA'] == 'SIM']\n",
    "\n",
    "    ativos = d['Ativo'].unique().tolist()\n",
    "    return [a for a in ativos if a in df_p.columns]\n",
    "\n",
    "\n",
    "def _ind_xs_series(metric: str, cols: list[str]) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Série diária cross-section para a indústria (sem encadear períodos).\n",
    "    - 'ret': robust_cross_section_mean dos retornos diários\n",
    "    - 'vol': média aparada da vol diária (%)\n",
    "    - 'sharpe': média aparada do Sharpe diário\n",
    "    Em todos os casos, aplica suavização ROLL_MM.\n",
    "    \"\"\"\n",
    "    if not cols:\n",
    "        return pd.Series(dtype='float64')\n",
    "\n",
    "    if metric == 'ret':\n",
    "        arr = df_ret_full[cols]\n",
    "        xs = robust_cross_section_mean(arr)\n",
    "    elif metric == 'vol':\n",
    "        arr = df_vol_full[cols]\n",
    "        xs = arr.apply(trim_mean_series, axis=1)\n",
    "    else:  # 'sharpe'\n",
    "        arr = sharpe_full[cols]\n",
    "        xs = arr.apply(trim_mean_series, axis=1)\n",
    "\n",
    "    xs = xs.rolling(ROLL_MM, min_periods=1).mean()\n",
    "    return xs.dropna()\n",
    "\n",
    "\n",
    "def industry_rebalanced_series(metric: str, selected_filters, sd, ed):\n",
    "    \"\"\"\n",
    "    Constrói a série de MÉDIA DA INDÚSTRIA com rebalanceamento ANUAL:\n",
    "      - Janela fixa: WINDOW48_START → WINDOW48_END (48 meses)\n",
    "      - Cohort fixo entre datas de rebalance (30/06 de cada ano)\n",
    "      - Filtros MEG aplicados NA DATA DO REBALANCE\n",
    "    Retorna: (serie, dict_contagem_por_ano, sd_efetivo, ed_efetivo)\n",
    "    \"\"\"\n",
    "    sd = pd.to_datetime(sd); ed = pd.to_datetime(ed)\n",
    "    sd = max(sd, WINDOW48_START); ed = min(ed, WINDOW48_END)\n",
    "    if sd >= ed:\n",
    "        return pd.Series(dtype='float64'), {}, sd, ed\n",
    "\n",
    "    seg_series = []\n",
    "    counts_by_year = {}\n",
    "\n",
    "    # percorre os blocos entre rebalances\n",
    "    for i in range(len(REBAL_DATES) - 1):\n",
    "        r0, r1 = REBAL_DATES[i], REBAL_DATES[i + 1]  # [r0, r1]\n",
    "        seg_start = max(sd, r0)\n",
    "        seg_end   = min(ed, r1)\n",
    "        if seg_start >= seg_end:\n",
    "            continue\n",
    "\n",
    "        cohort_all = get_allowed_activos_at(r0, selected_filters)\n",
    "\n",
    "        # mantém apenas fundos com dados no período do segmento\n",
    "        if metric == 'ret':\n",
    "            cols = [c for c in cohort_all if not df_ret_full[c].loc[seg_start:seg_end].dropna().empty]\n",
    "        elif metric == 'vol':\n",
    "            cols = [c for c in cohort_all if not df_vol_full[c].loc[seg_start:seg_end].dropna().empty]\n",
    "        else:\n",
    "            cols = [c for c in cohort_all if not sharpe_full[c].loc[seg_start:seg_end].dropna().empty]\n",
    "\n",
    "        if not cols:\n",
    "            continue\n",
    "\n",
    "        counts_by_year[r0.year] = len(cols)\n",
    "\n",
    "        s = _ind_xs_series(metric, cols).loc[seg_start:seg_end]\n",
    "        if not s.empty:\n",
    "            seg_series.append(s)\n",
    "\n",
    "    if not seg_series:\n",
    "        return pd.Series(dtype='float64'), counts_by_year, sd, ed\n",
    "\n",
    "    s = pd.concat(seg_series).sort_index()\n",
    "\n",
    "    if metric == 'ret':\n",
    "        s = (1 + s).cumprod()\n",
    "        s = (s / s.iloc[0]) * 100.0\n",
    "\n",
    "    return s, counts_by_year, sd, ed\n",
    "\n",
    "\n",
    "\n",
    "def winsorize_series(s, q_low=SH_LOW_Q, q_high=SH_HIGH_Q):\n",
    "    if s.dropna().empty:\n",
    "        return s\n",
    "    ql, qh = s.quantile([q_low, 1 - q_high])\n",
    "    return s.clip(lower=ql, upper=qh)\n",
    "\n",
    "def mad_clip_series(s, k=MAD_K):\n",
    "    med = s.median()\n",
    "    mad = (s - med).abs().median()\n",
    "    if mad == 0 or pd.isna(mad):\n",
    "        return s\n",
    "    return s.clip(lower=med - k * mad, upper=med + k * mad)\n",
    "\n",
    "def safe_winsor_mad(col):\n",
    "    s = col.dropna()\n",
    "    if len(s) < 30:\n",
    "        return col\n",
    "    s = winsorize_series(s)\n",
    "    s = mad_clip_series(s)\n",
    "    return col.combine_first(s)\n",
    "\n",
    "def rebase100(series):\n",
    "    if series is None or len(series) == 0:\n",
    "        return series\n",
    "    first = series.iloc[0]\n",
    "    if pd.isna(first) or first == 0:\n",
    "        return series\n",
    "    return series / first * 100\n",
    "\n",
    "# lista de fundos base (sem filtros)\n",
    "funds = [f for f in df_p.columns if f in mapping]\n",
    "\n",
    "def get_allowed_activos(selected_filters):\n",
    "    # se não há filtros selecionados, retorna todos os fundos\n",
    "    if not selected_filters:\n",
    "        return funds\n",
    "    df_f = df_all.copy()\n",
    "    for f in selected_filters:\n",
    "        df_f = df_f[filter_funcs[f](df_f)]\n",
    "    ativos = df_f['Ativo'].unique().tolist()\n",
    "    # garante só códigos que existam em df_p\n",
    "    return [a for a in ativos if a in df_p.columns]\n",
    "\n",
    "def start_at_first_valid(s: pd.Series) -> pd.Series:\n",
    "    if s is None or s.empty:\n",
    "        return s\n",
    "    idx = s.first_valid_index()\n",
    "    return s.loc[idx:] if idx is not None else s\n",
    "\n",
    "\n",
    "\n",
    "def base100_from(s: pd.Series) -> pd.Series:\n",
    "    # rebase em 100 a partir da 1ª observação válida\n",
    "    s = s.dropna()\n",
    "    if s.empty:\n",
    "        return s\n",
    "    return (s / s.iloc[0]) * 100\n",
    "\n",
    "def _annot_fig(title, msg, height=350):\n",
    "    fig = go.Figure()\n",
    "    fig.update_layout(template='plotly_white', title=title, height=height)\n",
    "    fig.add_annotation(text=msg, x=0.5, y=0.5, xref='paper', yref='paper',\n",
    "                       showarrow=False, font=dict(size=14))\n",
    "    return fig\n",
    "# --- helper: pega o 1º valor válido e rebasa em 100 ---\n",
    "def base100_series(s: pd.Series) -> pd.Series:\n",
    "    s = s.dropna()\n",
    "    if s.empty:\n",
    "        return s\n",
    "    return (s / s.iloc[0]) * 100\n",
    "\n",
    "def _empty_fig(title, msg, height=350):\n",
    "    return _annot_fig(title, msg, height)\n",
    "\n",
    "\n",
    "\n",
    "# ---------- Fonte única para mortalidade: df_life_all ----------\n",
    "_life_df = globals().get(\"df_life_all\", None)\n",
    "if _life_df is None or not isinstance(_life_df, pd.DataFrame):\n",
    "    _life_df = pd.DataFrame(columns=[\"Codigo\", \"CodigoFinal\", \"Nome\"])\n",
    "\n",
    "# coluna de código final (numérica)\n",
    "_code_col = \"CodigoFinal\" if \"CodigoFinal\" in _life_df.columns else (\"Codigo\" if \"Codigo\" in _life_df.columns else None)\n",
    "\n",
    "# mapping pode não existir\n",
    "_mapping = globals().get(\"mapping\", {}) or {}\n",
    "\n",
    "def label_for_code(code: str) -> str:\n",
    "    code = str(code)\n",
    "    # 1) nome pelo mapping (prefixo do Ativo começa com o código)\n",
    "    nm = next((v for k, v in _mapping.items() if str(k).startswith(code)), None)\n",
    "    if nm:\n",
    "        return nm\n",
    "    # 2) nome vindo da planilha\n",
    "    if _code_col and \"Nome\" in _life_df.columns:\n",
    "        row = _life_df.loc[_life_df[_code_col].astype(str) == code, \"Nome\"]\n",
    "        if not row.empty:\n",
    "            val = str(row.iloc[0]).strip()\n",
    "            if val:\n",
    "                return val\n",
    "    # 3) fallback\n",
    "    return code\n",
    "\n",
    "# códigos únicos (ordenados por label)\n",
    "if _code_col:\n",
    "    codes = (\n",
    "        _life_df[_code_col]\n",
    "        .astype(str).str.strip()\n",
    "        .replace(\"\", np.nan).dropna()\n",
    "        .drop_duplicates()\n",
    "        .tolist()\n",
    "    )\n",
    "    codes.sort(key=lambda c: (label_for_code(c) or \"\").lower())\n",
    "else:\n",
    "    codes = []\n",
    "\n",
    "fund_opts = [{\"label\": label_for_code(c), \"value\": c} for c in codes]\n",
    "default_values = [codes[0]] if codes else []\n",
    "default_code   = default_values[0] if default_values else None  # se algum ponto do código ainda espera escalar\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "excess_ret   = df_ret_full.sub(cdi_ret_daily, axis=0)\n",
    "roll_mean_e  = excess_ret.rolling(WINDOW, min_periods=MINP).mean()\n",
    "roll_std     = df_ret_full.rolling(WINDOW, min_periods=MINP).std().replace(0, np.nan)\n",
    "sharpe_full  = (roll_mean_e / roll_std).apply(safe_winsor_mad).replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "df_ret   = df_ret_full[df_ret_full.index >= START_FILTER]\n",
    "df_vol   = df_vol_full[df_vol_full.index >= START_FILTER]\n",
    "df_sh    = sharpe_full[sharpe_full.index >= START_FILTER]\n",
    "\n",
    "ret_cs_mean = robust_cross_section_mean(df_ret)\n",
    "ret_cs_mm   = ret_cs_mean.rolling(ROLL_MM, min_periods=1).mean()\n",
    "ret_ind     = rebase100((1 + ret_cs_mm).cumprod())\n",
    "\n",
    "vol_tmp     = df_vol / SCALE_FIX\n",
    "vol_cs_mean = vol_tmp.apply(trim_mean_series, axis=1)\n",
    "vol_ind     = vol_cs_mean.rolling(ROLL_MM, min_periods=1).mean()\n",
    "\n",
    "sh_cs_mean  = df_sh.apply(trim_mean_series, axis=1)\n",
    "sh_ind      = sh_cs_mean.rolling(ROLL_MM, min_periods=1).mean()\n",
    "\n",
    "ativos_por_ano = (\n",
    "    df_p.stack(dropna=True)\n",
    "        .reset_index(level=1)\n",
    "        .rename(columns={\"level_1\": \"Ativo\", 0: \"Preco\"})\n",
    "        .assign(Ano=lambda d: d.index.year)\n",
    "        .groupby(\"Ano\")[\"Ativo\"].nunique()\n",
    ")\n",
    "\n",
    "# ======================\n",
    "# UI: dropdowns e filtros\n",
    "# ======================\n",
    "metricas = [\n",
    "    {'label': 'Retorno Acumulado', 'value': 'retorno'},\n",
    "    {'label': 'Volatilidade',      'value': 'volatilidade'},\n",
    "    {'label': 'Sharpe',            'value': 'sharpe'}\n",
    "]\n",
    "\n",
    "filter_options = [\n",
    "    {'label': 'Patrimônio > 300 mi', 'value': 'patrimonio'},\n",
    "    {'label': 'Atuação > 4 anos',    'value': 'atuacao'},\n",
    "    {'label': 'Cotistas > 100',      'value': 'cotistas'},\n",
    "    {'label': 'Sem multigestor/espelho', 'value': 'multigestor'},\n",
    "    {'label': 'Fundo exclusivo ≠ Sim',   'value': 'exclusivo'},\n",
    "    {'label': 'Condomínio aberto',       'value': 'condominio'},\n",
    "    {'label': \"Investimento no Exterior ‘Até 40%%’ excluído\", 'value': 'exterior'},\n",
    "    {'label': 'Restritos ≠ Sim',         'value': 'restrito'},\n",
    "    {'label': 'Gestora com histórico IHFA', 'value': 'ihfa'},\n",
    "]\n",
    "\n",
    "app = dash.Dash(__name__, suppress_callback_exceptions=True)\n",
    "\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from dash import html, dcc\n",
    "\n",
    "def serve_layout():\n",
    "    \"\"\"\n",
    "    Layout seguro: lida com ausências de dados/arquivos, normaliza limites de datas\n",
    "    e evita NameError/KeyError vindo de variáveis globais.\n",
    "    \"\"\"\n",
    "    # Datas-base para seletores\n",
    "    today = datetime.today().date()\n",
    "    ten_years_ago = today - timedelta(days=3650)\n",
    "\n",
    "    # ─────────────────────────────────────────────────────────────────────────────\n",
    "    # Bases globais com fallback seguro\n",
    "    # ─────────────────────────────────────────────────────────────────────────────\n",
    "    _life_df   = globals().get(\"df_life_all\")\n",
    "    _mapping   = globals().get(\"mapping\") or {}\n",
    "    _df_ret    = globals().get(\"df_ret_full\", pd.DataFrame(index=pd.to_datetime([])))\n",
    "    _ret_ind   = globals().get(\"ret_ind\", pd.Series(dtype=\"float64\"))\n",
    "    _cdi_idx   = globals().get(\"cdi_idx\", pd.Series(dtype=\"float64\"))\n",
    "    funds_local = list(globals().get(\"funds\") or [])\n",
    "    filter_opts = list(globals().get(\"filter_options\") or [])\n",
    "\n",
    "    # Mortalidade: dataframe mínimo se não houver\n",
    "    if not isinstance(_life_df, pd.DataFrame):\n",
    "        _life_df = pd.DataFrame(columns=[\"Codigo\", \"CodigoFinal\", \"Nome\", \"DataInicio\", \"DataFim\"])\n",
    "\n",
    "    # Coluna de código (preferir CodigoFinal)\n",
    "    _code_col = \"CodigoFinal\" if \"CodigoFinal\" in _life_df.columns else (\"Codigo\" if \"Codigo\" in _life_df.columns else None)\n",
    "\n",
    "    # Helper p/ rótulo: tenta mapping; se não, usa Nome da planilha; senão, o próprio código\n",
    "    def _label_for_code(code: str) -> str:\n",
    "        code = str(code)\n",
    "        nm = next((v for k, v in _mapping.items() if str(k).startswith(code)), None)\n",
    "        if nm:\n",
    "            return nm\n",
    "        if _code_col and \"Nome\" in _life_df.columns:\n",
    "            row = _life_df.loc[_life_df[_code_col].astype(str) == code, \"Nome\"]\n",
    "            if not row.empty:\n",
    "                val = str(row.iloc[0]).strip()\n",
    "                if val:\n",
    "                    return val\n",
    "        return code\n",
    "\n",
    "    # Opções do dropdown de mortalidade\n",
    "    if _code_col and not _life_df.empty:\n",
    "        all_codes = (\n",
    "            _life_df[_code_col]\n",
    "            .astype(str).str.strip()\n",
    "            .replace(\"\", pd.NA).dropna().unique().tolist()\n",
    "        )\n",
    "        all_codes.sort(key=lambda c: (_label_for_code(c) or \"\").lower())\n",
    "        fund_opts = [{\"label\": _label_for_code(c), \"value\": c} for c in all_codes]\n",
    "        default_values = [all_codes[0]] if all_codes else []\n",
    "    else:\n",
    "        fund_opts, default_values = [], []\n",
    "\n",
    "    # Limites do seletor de mortalidade (recalcula se não existirem/invalidos)\n",
    "    _MORT_MIN = globals().get(\"MORT_MIN\")\n",
    "    _MORT_MAX = globals().get(\"MORT_MAX\")\n",
    "\n",
    "    def _recompute_mort_bounds():\n",
    "        _dates = []\n",
    "        if \"DataInicio\" in _life_df.columns and _life_df[\"DataInicio\"].notna().any():\n",
    "            _dates.append(_life_df[\"DataInicio\"].dropna())\n",
    "        if \"DataFim\" in _life_df.columns and _life_df[\"DataFim\"].notna().any():\n",
    "            _dates.append(_life_df[\"DataFim\"].dropna())\n",
    "        if _dates:\n",
    "            _all = pd.concat(_dates, ignore_index=True)\n",
    "            return _all.min().normalize(), _all.max().normalize()\n",
    "        return pd.Timestamp(\"2000-01-01\"), pd.Timestamp.today().normalize()\n",
    "\n",
    "    if not isinstance(_MORT_MIN, pd.Timestamp) or not isinstance(_MORT_MAX, pd.Timestamp) or pd.isna(_MORT_MIN) or pd.isna(_MORT_MAX) or (_MORT_MIN > _MORT_MAX):\n",
    "        _MORT_MIN, _MORT_MAX = _recompute_mort_bounds()\n",
    "\n",
    "    # --------- helpers de datas seguras ----------\n",
    "    def _idx_bounds_from(series_like, fallback_min, fallback_max):\n",
    "        \"\"\"\n",
    "        Retorna (start_date, end_date) como objetos date, usando fallbacks se necessário.\n",
    "        Aceita Series/DataFrame indexados por DatetimeIndex.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if isinstance(series_like, (pd.Series, pd.DataFrame)) and not series_like.empty:\n",
    "                smin = series_like.index.min()\n",
    "                smax = series_like.index.max()\n",
    "                if pd.notna(smin) and pd.notna(smax):\n",
    "                    return smin.date(), smax.date()\n",
    "            # fallback\n",
    "            return pd.to_datetime(fallback_min).date(), pd.to_datetime(fallback_max).date()\n",
    "        except Exception:\n",
    "            return pd.to_datetime(fallback_min).date(), pd.to_datetime(fallback_max).date()\n",
    "\n",
    "    # bounds baseados no df_ret_full (fallback geral)\n",
    "    base_min = _df_ret.index.min() if not _df_ret.empty else pd.Timestamp(\"2010-01-01\")\n",
    "    base_max = _df_ret.index.max() if not _df_ret.empty else pd.Timestamp.today()\n",
    "\n",
    "    # DatePicker: CDI/IHFA/Meta (limitar a 10 anos)\n",
    "    cdi_start_all, cdi_end_all = _idx_bounds_from(_cdi_idx, base_min, base_max)\n",
    "    cdi_start_default = max(pd.to_datetime(cdi_start_all).date(), ten_years_ago)\n",
    "    cdi_end_default   = min(pd.to_datetime(cdi_end_all).date(), today)\n",
    "    if cdi_start_default > cdi_end_default:\n",
    "        # fallback coerente\n",
    "        cdi_start_default, cdi_end_default = cdi_start_all, cdi_end_all\n",
    "\n",
    "    # Indústria (usar ret_ind com fallback para df_ret_full)\n",
    "    ind_start_all, ind_end_all = _idx_bounds_from(\n",
    "        _ret_ind if isinstance(_ret_ind, (pd.Series, pd.DataFrame)) and not getattr(_ret_ind, \"empty\", True) else _df_ret,\n",
    "        base_min, base_max\n",
    "    )\n",
    "\n",
    "    # DatePickers que usam df_ret_full direto (com fallback)\n",
    "    df_start_all, df_end_all = _idx_bounds_from(_df_ret, base_min, base_max)\n",
    "\n",
    "    # Códigos de classes (podem não existir, então fallback)\n",
    "    macro_codes = list(globals().get(\"macro_codes\") or [])\n",
    "    ls_codes    = list(globals().get(\"ls_codes\") or [])\n",
    "    codes       = list(globals().get(\"codes\") or (macro_codes + ls_codes))\n",
    "\n",
    "    # Fundos/códigos do PCA (podem não existir)\n",
    "    fund_options = list(globals().get(\"fund_options\") or [])\n",
    "    fund_codes   = list(globals().get(\"fund_codes\") or [])\n",
    "\n",
    "    # ─────────────────────────────────────────────────────────────────────────────\n",
    "    # Layout\n",
    "    # ─────────────────────────────────────────────────────────────────────────────\n",
    "    return html.Div(\n",
    "        [\n",
    "            html.H1(\"Painel FI Multimercado\", style={\"textAlign\": \"center\"}),\n",
    "\n",
    "            # Filtros MEG 143\n",
    "            html.H2(\"Filtros MEG 143\"),\n",
    "            dcc.Checklist(\n",
    "                id=\"meg-filters\",\n",
    "                options=filter_opts,\n",
    "                value=[],\n",
    "                inputStyle={\"marginRight\": \"5px\"}\n",
    "            ),\n",
    "\n",
    "            # Benchmarks: CDI, IHFA & Meta Atuarial\n",
    "            html.H2(\"Benchmarks: CDI, IHFA & Meta Atuarial\"),\n",
    "            dcc.Checklist(\n",
    "                id=\"benchmarks-selector\",\n",
    "                options=[\n",
    "                    {\"label\": \"CDI\", \"value\": \"cdi\"},\n",
    "                    {\"label\": \"IHFA\", \"value\": \"ihfa\"},\n",
    "                    {\"label\": \"Meta Atuarial\", \"value\": \"atu\"},\n",
    "                ],\n",
    "                value=[\"cdi\", \"ihfa\", \"atu\"],\n",
    "                inputStyle={\"marginRight\": \"5px\"}\n",
    "            ),\n",
    "\n",
    "            # Índice Acumulado (Base 100 no range)\n",
    "            html.H2(\"Índice Acumulado (Base 100 no range)\"),\n",
    "            dcc.DatePickerRange(\n",
    "                id=\"cdi-date-picker\",\n",
    "                start_date=cdi_start_default,\n",
    "                end_date=cdi_end_default,\n",
    "                min_date_allowed=cdi_start_all,\n",
    "                max_date_allowed=min(today, cdi_end_all),\n",
    "                display_format=\"YYYY-MM-DD\"\n",
    "            ),\n",
    "            dcc.Graph(id=\"cdi-chart\", style={\"marginTop\": \"20px\"}),\n",
    "\n",
    "            # ─────────────────────────────────────────────\n",
    "            # Mortalidade (ANUAL): Mortes/Ativos + bolhas Início/Fim\n",
    "            # ─────────────────────────────────────────────\n",
    "            html.H2(\"Mortalidade (Anual) — Mortes / Total de Fundos\"),\n",
    "            dcc.DatePickerRange(\n",
    "                id=\"mort-date-picker\",\n",
    "                start_date=_MORT_MIN.date(),\n",
    "                end_date=_MORT_MAX.date(),\n",
    "                min_date_allowed=_MORT_MIN.date(),\n",
    "                max_date_allowed=_MORT_MAX.date(),\n",
    "                display_format=\"YYYY-MM-DD\",\n",
    "                style={\"marginTop\": \"4px\"}\n",
    "            ),\n",
    "            dcc.Dropdown(\n",
    "                id=\"mort-fund-select\",\n",
    "                options=fund_opts,\n",
    "                value=default_values,\n",
    "                multi=True,\n",
    "                placeholder=\"Selecione um ou mais fundos…\",\n",
    "                clearable=True,\n",
    "                style={\"width\": \"50%\", \"marginTop\": \"10px\"}\n",
    "            ),\n",
    "            dcc.Graph(id=\"mortality-chart\", style={\"marginTop\": \"14px\"}),\n",
    "\n",
    "            # Médias da Indústria (Robustas, Base 100 no range)\n",
    "            html.H2(\"Médias da Indústria (Robustas, Base 100 no range)\"),\n",
    "            dcc.DatePickerRange(\n",
    "                id=\"ind-date-picker\",\n",
    "                start_date=ind_start_all,\n",
    "                end_date=ind_end_all,\n",
    "                min_date_allowed=ind_start_all,\n",
    "                max_date_allowed=ind_end_all,\n",
    "                display_format=\"YYYY-MM-DD\"\n",
    "            ),\n",
    "            dcc.RadioItems(\n",
    "                id=\"ind-metrics-selector\",\n",
    "                options=[\n",
    "                    {\"label\": \"Retorno Acumulado (Base 100)\", \"value\": \"ret\"},\n",
    "                    {\"label\": \"Volatilidade\", \"value\": \"vol\"},\n",
    "                    {\"label\": \"Sharpe\", \"value\": \"sharpe\"},\n",
    "                ],\n",
    "                value=\"ret\",\n",
    "                inline=True,\n",
    "                style={\"marginTop\": \"10px\"},\n",
    "                inputStyle={\"marginRight\": \"6px\"}\n",
    "            ),\n",
    "            dcc.Dropdown(\n",
    "                id=\"ind-funds-compare\",\n",
    "                options=[{\"label\": _mapping.get(a, a), \"value\": a} for a in funds_local],\n",
    "                value=[],\n",
    "                multi=True,\n",
    "                placeholder=\"Selecione fundos para comparar com a média da indústria\",\n",
    "                style={\"width\": \"60%\", \"marginTop\": \"10px\"}\n",
    "            ),\n",
    "            dcc.Graph(id=\"ind-comp-chart\", style={\"marginTop\": \"20px\"}),\n",
    "\n",
    "            html.Div(\n",
    "                [\n",
    "                    dcc.Graph(id=\"ret-ind-chart\"),\n",
    "                    dcc.Graph(id=\"vol-ind-chart\"),\n",
    "                    dcc.Graph(id=\"sh-ind-chart\"),\n",
    "                    dcc.Graph(id=\"ativos-chart\"),\n",
    "                ],\n",
    "                style={\n",
    "                    \"display\": \"grid\",\n",
    "                    \"gridTemplateColumns\": \"1fr 1fr\",\n",
    "                    \"gap\": \"20px\",\n",
    "                    \"marginTop\": \"40px\"\n",
    "                }\n",
    "            ),\n",
    "\n",
    "            # Correlação de Retornos Diários\n",
    "            html.H2(\"Correlação de Retornos Diários\"),\n",
    "            dcc.DatePickerRange(\n",
    "                id=\"corr-date-picker\",\n",
    "                start_date=df_start_all,\n",
    "                end_date=df_end_all,\n",
    "                min_date_allowed=df_start_all,\n",
    "                max_date_allowed=df_end_all,\n",
    "                display_format=\"YYYY-MM-DD\",\n",
    "                style={\"marginTop\": \"20px\"}\n",
    "            ),\n",
    "            html.Div(\n",
    "                [\n",
    "                    dcc.Graph(id=\"macro-corr-heatmap\", style={\"width\": \"100%\", \"marginTop\": \"40px\"}),\n",
    "                    dcc.Graph(id=\"ls-corr-heatmap\", style={\"width\": \"100%\", \"marginTop\": \"40px\"}),\n",
    "                ],\n",
    "                style={\"display\": \"flex\", \"flexDirection\": \"column\", \"gap\": \"40px\"}\n",
    "            ),\n",
    "\n",
    "            # Correlação Rolling (ρ)\n",
    "            html.H2(\"Correlação Rolling (ρ)\"),\n",
    "            dcc.DatePickerRange(\n",
    "                id=\"rolling-corr-date-picker\",\n",
    "                start_date=df_start_all,\n",
    "                end_date=df_end_all,\n",
    "                min_date_allowed=df_start_all,\n",
    "                max_date_allowed=df_end_all,\n",
    "                display_format=\"YYYY-MM-DD\",\n",
    "                style={\"marginBottom\": \"10px\"}\n",
    "            ),\n",
    "            html.Label(\"Selecione até dois fundos:\"),\n",
    "            dcc.Dropdown(\n",
    "                id=\"fund-selector\",\n",
    "                options=[{\"label\": _mapping.get(a, a), \"value\": a} for a in funds_local],\n",
    "                value=funds_local[:2] if len(funds_local) >= 2 else funds_local,\n",
    "                multi=True,\n",
    "                searchable=True,\n",
    "                placeholder=\"Digite e selecione fundos...\",\n",
    "                style={\"width\": \"60%\", \"marginBottom\": \"20px\"}\n",
    "            ),\n",
    "            dcc.Graph(id=\"rolling-corr-graph\", style={\"marginBottom\": \"40px\"}),\n",
    "\n",
    "            # Correlação Média x PL x Volatilidade\n",
    "            html.H2(\"Correlação Média x PL x Volatilidade\"),\n",
    "            html.Div(\n",
    "                [\n",
    "                    dcc.DatePickerRange(\n",
    "                        id=\"corrpl-date-picker\",\n",
    "                        start_date=df_start_all,\n",
    "                        end_date=df_end_all,\n",
    "                        min_date_allowed=df_start_all,\n",
    "                        max_date_allowed=df_end_all,\n",
    "                        display_format=\"YYYY-MM-DD\",\n",
    "                    ),\n",
    "                    dcc.RadioItems(\n",
    "                        id=\"corrpl-group\",\n",
    "                        options=[\n",
    "                            {\"label\": \"Todos\",              \"value\": \"all\"},\n",
    "                            {\"label\": \"Todos - Macro\",      \"value\": \"macro\"},\n",
    "                            {\"label\": \"Todos - Long/Short\", \"value\": \"ls\"},\n",
    "                        ],\n",
    "                        value=\"all\",\n",
    "                        inline=True,\n",
    "                        style={\"marginLeft\": \"16px\"}\n",
    "                    ),\n",
    "                ],\n",
    "                style={\"display\": \"flex\", \"alignItems\": \"center\", \"gap\": \"16px\",\n",
    "                       \"flexWrap\": \"wrap\", \"marginBottom\": \"8px\"}\n",
    "            ),\n",
    "            dcc.Dropdown(\n",
    "                id=\"corrpl-highlight\",\n",
    "                options=[{\"label\": f\"{_mapping.get(a,a)} ({a})\", \"value\": a}\n",
    "                         for a in funds_local if any(a.startswith(code) for code in (macro_codes + ls_codes))],\n",
    "                value=None,\n",
    "                placeholder=\"Destaque um fundo (opcional)…\",\n",
    "                style={\"width\": \"40%\", \"marginBottom\": \"8px\"}\n",
    "            ),\n",
    "            dcc.Graph(id=\"corrpl-scatter\", style={\"marginBottom\": \"40px\"}),\n",
    "\n",
    "            # Bubble Chart 3D\n",
    "            html.H2(\"Bubble Chart 3D: Correlação × Volatilidade × Retorno\"),\n",
    "            html.Div(\n",
    "                [\n",
    "                    dcc.DatePickerRange(\n",
    "                        id=\"bubble-date-picker\",\n",
    "                        start_date=START_FILTER.date(),\n",
    "                        end_date=today,\n",
    "                        min_date_allowed=START_FILTER.date(),\n",
    "                        max_date_allowed=today,\n",
    "                        display_format=\"YYYY-MM-DD\",\n",
    "                        style={\"marginRight\": \"20px\"}\n",
    "                    ),\n",
    "                    dcc.Dropdown(\n",
    "                        id=\"bubble-funds-select\",\n",
    "                        options=[\n",
    "                            {\"label\": _mapping.get(a, a), \"value\": a}\n",
    "                            for a in funds_local\n",
    "                            if any(a.startswith(code) for code in macro_codes + ls_codes)\n",
    "                        ],\n",
    "                        multi=True,\n",
    "                        placeholder=\"Selecione fundos...\",\n",
    "                        style={\"width\": \"400px\"}\n",
    "                    ),\n",
    "                ],\n",
    "                style={\"display\": \"flex\", \"alignItems\": \"center\", \"marginBottom\": \"20px\"}\n",
    "            ),\n",
    "            dcc.Graph(id=\"bubble3d\", style={\"marginBottom\": \"40px\"}),\n",
    "\n",
    "            # PCA 2D\n",
    "            html.H2(\"PCA 2D de Fundos Multimercado\"),\n",
    "            html.Div(\n",
    "                [\n",
    "                    dcc.Dropdown(\n",
    "                        id=\"pca-fundos\",\n",
    "                        options=fund_options,\n",
    "                        value=fund_codes[:5] if fund_codes else [],\n",
    "                        multi=True,\n",
    "                        placeholder=\"Selecione fundos...\",\n",
    "                        style={\"width\": \"300px\", \"marginRight\": \"20px\"}\n",
    "                    ),\n",
    "                    dcc.DatePickerRange(\n",
    "                        id=\"pca-date-range\",\n",
    "                        start_date=START_FILTER.date(),\n",
    "                        end_date=today,\n",
    "                        display_format=\"YYYY-MM-DD\"\n",
    "                    ),\n",
    "                ],\n",
    "                style={\"display\": \"flex\", \"alignItems\": \"center\", \"marginBottom\": \"20px\"}\n",
    "            ),\n",
    "            dcc.Graph(id=\"pca-graph\", style={\"height\": \"600px\"}),\n",
    "\n",
    "            # Dendrograma por Faixa de Volatilidade\n",
    "            html.H2(\"Dendrograma por Faixa de Volatilidade\"),\n",
    "            html.Div(\n",
    "                [\n",
    "                    html.Div(\n",
    "                        [\n",
    "                            html.Label(\"Faixa de Volatilidade (anualizada, %)\"),\n",
    "                            dcc.RangeSlider(\n",
    "                                id=\"dendo-vol-range\",\n",
    "                                min=0, max=60, step=0.5,\n",
    "                                value=[5, 25],\n",
    "                                allowCross=False,\n",
    "                                marks={i: f\"{i}%\" for i in range(0, 61, 5)},\n",
    "                                tooltip={\"always_visible\": False, \"placement\": \"bottom\"}\n",
    "                            ),\n",
    "                        ],\n",
    "                        style={\"width\": \"48%\", \"display\": \"inline-block\",\n",
    "                               \"verticalAlign\": \"top\", \"paddingRight\": \"10px\"}\n",
    "                    ),\n",
    "                    html.Div(\n",
    "                        [\n",
    "                            html.Label(\"Selecione os Fundos\"),\n",
    "                            dcc.Dropdown(\n",
    "                                id=\"dendo-funds-select\",\n",
    "                                options=[\n",
    "                                    {\"label\": _mapping.get(c, c), \"value\": c}\n",
    "                                    for c in funds_local if any(c.startswith(code) for code in codes)\n",
    "                                ],\n",
    "                                value=[c for c in funds_local if any(c.startswith(code) for code in codes)][:10],\n",
    "                                multi=True,\n",
    "                                placeholder=\"Escolha os fundos para o dendrograma...\"\n",
    "                            ),\n",
    "                        ],\n",
    "                        style={\"width\": \"48%\", \"display\": \"inline-block\", \"verticalAlign\": \"top\"}\n",
    "                    ),\n",
    "                ],\n",
    "                style={\"marginBottom\": \"10px\"}\n",
    "            ),\n",
    "            dcc.Graph(id=\"dendo-graph\", style={\"height\": \"700px\"}),\n",
    "\n",
    "            # Análise por Fundo (Base 100 no range)\n",
    "            html.H2(\"Análise por Fundo (Base 100 no range)\"),\n",
    "            html.Div(\n",
    "                [\n",
    "                    html.Div(\n",
    "                        [\n",
    "                            dcc.Dropdown(\n",
    "                                id=f\"fund{i}-dropdown\",\n",
    "                                options=[{\"label\": _mapping.get(a, a), \"value\": a} for a in funds_local],\n",
    "                                placeholder=f\"Fundo {i}\"\n",
    "                            ) for i in range(1, 6)\n",
    "                        ],\n",
    "                        style={\"display\": \"grid\", \"gridTemplateColumns\": \"repeat(5, 1fr)\", \"gap\": \"10px\"}\n",
    "                    ),\n",
    "                    dcc.Dropdown(\n",
    "                        id=\"metric-dropdown\",\n",
    "                        options=[\n",
    "                            {\"label\": \"Retorno Acumulado\", \"value\": \"retorno\"},\n",
    "                            {\"label\": \"Volatilidade\", \"value\": \"volatilidade\"},\n",
    "                            {\"label\": \"Sharpe\", \"value\": \"sharpe\"}\n",
    "                        ],\n",
    "                        value=\"retorno\",\n",
    "                        style={\"width\": \"30%\", \"marginTop\": \"20px\"}\n",
    "                    ),\n",
    "                    dcc.Checklist(\n",
    "                        id=\"fund-benchmarks-selector\",\n",
    "                        options=[\n",
    "                            {\"label\": \"CDI\",  \"value\": \"cdi\"},\n",
    "                            {\"label\": \"IHFA\", \"value\": \"ihfa\"},\n",
    "                            {\"label\": \"Meta Atuarial\", \"value\": \"atu\"}\n",
    "                        ],\n",
    "                        value=[\"cdi\", \"ihfa\", \"atu\"],\n",
    "                        inputStyle={\"marginRight\": \"5px\"},\n",
    "                        style={\"marginTop\": \"20px\"}\n",
    "                    ),\n",
    "                    dcc.DatePickerRange(\n",
    "                        id=\"fund-date-picker\",\n",
    "                        start_date=df_start_all,\n",
    "                        end_date=df_end_all,\n",
    "                        min_date_allowed=df_start_all,\n",
    "                        max_date_allowed=df_end_all,\n",
    "                        display_format=\"YYYY-MM-DD\",\n",
    "                        style={\"marginTop\": \"20px\"}\n",
    "                    ),\n",
    "                    dcc.Graph(id=\"fund-metric-chart\", style={\"marginTop\": \"20px\"}),\n",
    "                ],\n",
    "                style={\"marginTop\": \"20px\"}\n",
    "            ),\n",
    "        ],\n",
    "        style={\"maxWidth\": \"1600px\", \"width\": \"95%\", \"margin\": \"0 auto\", \"padding\": \"20px\"}\n",
    "    )\n",
    "\n",
    "# Vincule o layout/servidor APENAS uma vez, fora da função:\n",
    "app.layout = serve_layout\n",
    "server = app.server\n",
    "\n",
    "\n",
    "from datetime import timedelta\n",
    "\n",
    "from datetime import timedelta\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from dash.dependencies import Input, Output\n",
    "\n",
    "@app.callback(\n",
    "    Output('cdi-chart', 'figure'),\n",
    "    Input('benchmarks-selector', 'value'),\n",
    "    Input('cdi-date-picker',      'start_date'),\n",
    "    Input('cdi-date-picker',      'end_date'),\n",
    ")\n",
    "def update_cdi_chart(benchmarks, start_date, end_date):\n",
    "    # 1) converte datas e limita a 10 anos\n",
    "    sd = pd.to_datetime(start_date)\n",
    "    ed = pd.to_datetime(end_date)\n",
    "    if (ed - sd).days > 3650:\n",
    "        sd = ed - timedelta(days=3650)\n",
    "\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # 2) CDI (Base 100 diário)\n",
    "    if 'cdi' in benchmarks:\n",
    "        cdi_daily = cdi_idx.loc[sd:ed].copy()\n",
    "        if not cdi_daily.empty:\n",
    "            ret_d = cdi_daily.pct_change().fillna(0)\n",
    "            cum_d = (1 + ret_d).cumprod()\n",
    "            base = cum_d.iloc[0]\n",
    "            if base != 0 and not pd.isna(base):\n",
    "                s_cdi = cum_d.div(base).mul(100)\n",
    "                fig.add_trace(go.Scatter(\n",
    "                    x=s_cdi.index,\n",
    "                    y=s_cdi.values,\n",
    "                    mode='lines',\n",
    "                    name='CDI (Base 100 Diário)'\n",
    "                ))\n",
    "\n",
    "    # 3) IHFA (Base 100 diário)\n",
    "    if 'ihfa' in benchmarks:\n",
    "        ihfa_daily = ihfa_idx.loc[sd:ed].copy()\n",
    "        if not ihfa_daily.empty:\n",
    "            ret_i = ihfa_daily.pct_change().fillna(0)\n",
    "            cum_i = (1 + ret_i).cumprod()\n",
    "            base_i = cum_i.iloc[0]\n",
    "            if base_i != 0 and not pd.isna(base_i):\n",
    "                s_ihfa = cum_i.div(base_i).mul(100)\n",
    "                fig.add_trace(go.Scatter(\n",
    "                    x=s_ihfa.index,\n",
    "                    y=s_ihfa.values.flatten(),\n",
    "                    mode='lines',\n",
    "                    name='IHFA (Base 100 Diário)'\n",
    "                ))\n",
    "\n",
    "    # 4) Meta Atuarial (Base 100)\n",
    "    if 'atu' in benchmarks:\n",
    "        atu_slice = atu_series.loc[sd:ed].dropna()\n",
    "        if not atu_slice.empty:\n",
    "            base_a = atu_slice.iloc[0]\n",
    "            if base_a != 0 and not pd.isna(base_a):\n",
    "                s_atu = atu_slice.div(base_a).mul(100)\n",
    "                fig.add_trace(go.Scatter(\n",
    "                    x=s_atu.index,\n",
    "                    y=s_atu.values,\n",
    "                    mode='lines',\n",
    "                    name='Meta Atuarial (Base 100)'\n",
    "                ))\n",
    "\n",
    "    # 5) layout final\n",
    "    fig.update_layout(\n",
    "        title='Índices Acumulados (Base 100)',\n",
    "        xaxis_title='Data',\n",
    "        yaxis_title='Índice (Base 100)',\n",
    "        template='plotly_white',\n",
    "        height=400\n",
    "    )\n",
    "    fig.update_yaxes(tickformat='.2f')\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "# ======================\n",
    "# CALLBACK: INDÚSTRIA (com linha estática sem MEG)\n",
    "# ======================\n",
    "@app.callback(\n",
    "    Output('ret-ind-chart', 'figure'),\n",
    "    Output('vol-ind-chart', 'figure'),\n",
    "    Output('sh-ind-chart', 'figure'),\n",
    "    Output('ativos-chart', 'figure'),\n",
    "    Input('ind-date-picker', 'start_date'),\n",
    "    Input('ind-date-picker', 'end_date'),\n",
    "    Input('meg-filters', 'value')\n",
    ")\n",
    "def update_industry_charts(start_date, end_date, selected_filters):\n",
    "    sd = pd.to_datetime(start_date)\n",
    "    ed = pd.to_datetime(end_date)\n",
    "\n",
    "    # === TRAVA DA JANELA (fixa 30/06/2021 → 30/06/2025) ===\n",
    "    LOCK_START = pd.Timestamp(\"2021-06-30\")\n",
    "    LOCK_END   = pd.Timestamp(\"2025-06-30\")\n",
    "    sd, ed     = LOCK_START, LOCK_END\n",
    "\n",
    "    # MEG ativo? (há ao menos 1 filtro)\n",
    "    meg_active = bool(selected_filters)\n",
    "    # universo MEG: se não houver filtros, usa TODOS os fundos\n",
    "    ativos = get_allowed_activos(selected_filters or [])\n",
    "    if not meg_active:\n",
    "        ativos = funds[:]  # todos\n",
    "\n",
    "    # ======================\n",
    "    # Helpers do REBALANCEAMENTO (apenas para a linha MEG) + contagem anual\n",
    "    # ======================\n",
    "    WINDOW_START = pd.Timestamp(\"2021-06-30\")\n",
    "    DATA_MIN = df_ret_full.index.min()\n",
    "    DATA_MAX = df_ret_full.index.max()\n",
    "    RANGE_START = max(sd, WINDOW_START, DATA_MIN)\n",
    "    RANGE_END   = min(ed, DATA_MAX)\n",
    "\n",
    "    def clamp_dates(s0, s1):\n",
    "        s0 = max(pd.to_datetime(s0), DATA_MIN)\n",
    "        s1 = min(pd.to_datetime(s1), DATA_MAX)\n",
    "        return s0, s1\n",
    "\n",
    "    def gen_rebal_dates(start, end):\n",
    "        \"\"\"Quebra em janelas com âncora 30/06 de cada ano.\"\"\"\n",
    "        if start >= end:\n",
    "            return pd.to_datetime([start, end])\n",
    "        dates = [start]\n",
    "        y = max(2021, start.year)\n",
    "        anchor = pd.Timestamp(year=y, month=6, day=30)\n",
    "        if anchor <= start:\n",
    "            y += 1\n",
    "            anchor = pd.Timestamp(year=y, month=6, day=30)\n",
    "        while anchor < end:\n",
    "            dates.append(anchor)\n",
    "            y += 1\n",
    "            anchor = pd.Timestamp(year=y, month=6, day=30)\n",
    "        dates.append(end)\n",
    "        return pd.to_datetime(dates)\n",
    "\n",
    "    def get_allowed_activos_at(ref_date, filters):\n",
    "        \"\"\"Aplica filtros MEG NA DATA DO REBAL (atuacao dinâmica).\"\"\"\n",
    "        d = df_all.copy()\n",
    "        filters = filters or []\n",
    "        for f in filters:\n",
    "            if f == 'patrimonio':\n",
    "                d = d[d['Patrimônio|||em milhares'] > 300_000]\n",
    "            elif f == 'atuacao':\n",
    "                cutoff = ref_date - pd.DateOffset(years=ANOS_ATUACAO_MIN)\n",
    "                d = d[d['Data do|Início da Série'] <= cutoff]\n",
    "            elif f == 'cotistas':\n",
    "                d = d[d['Média de|Cotistas|1 mês|em unidades'] > 100]\n",
    "            elif f == 'multigestor':\n",
    "                d = d[~d['Multigestor'].isin(['Multigestor', 'Espelho'])]\n",
    "            elif f == 'exclusivo':\n",
    "                d = d[d['Fundo|exclusivo'] != 'Sim']\n",
    "            elif f == 'condominio':\n",
    "                d = d[d['Forma de|condomínio'] != 'Fechado']\n",
    "            elif f == 'exterior':\n",
    "                d = d[~d['Investimento|no Exterior'].isin(['', 'Até 100%'])]\n",
    "            elif f == 'restrito':\n",
    "                d = d[d['Restrito'] != 'Sim']\n",
    "            elif f == 'ihfa':\n",
    "                d = d[d['Gestora com histórico IHFA'] == 'SIM']\n",
    "        ativos_ok = d['Ativo'].unique().tolist()\n",
    "        return [a for a in ativos_ok if a in df_p.columns]\n",
    "\n",
    "    def _ind_xs_series(metric, cols):\n",
    "        \"\"\"Série diária cross-section (média robusta) com suavização ROLL_MM.\"\"\"\n",
    "        if not cols:\n",
    "            return pd.Series(dtype='float64')\n",
    "        if metric == 'ret':\n",
    "            arr = df_ret_full[cols]\n",
    "            xs = robust_cross_section_mean(arr)\n",
    "        elif metric == 'vol':\n",
    "            arr = df_vol_full[cols]\n",
    "            xs = arr.apply(trim_mean_series, axis=1)\n",
    "        else:  # 'sharpe'\n",
    "            arr = sharpe_full[cols]\n",
    "            xs = arr.apply(trim_mean_series, axis=1)\n",
    "        return xs.rolling(ROLL_MM, min_periods=1).mean().dropna()\n",
    "\n",
    "    def industry_meg_rebalanced(metric, s0, s1):\n",
    "        \"\"\"Constrói a linha MEG rebalanced: coorte por janela 30/06→30/06 e contagem anual.\"\"\"\n",
    "        s0, s1 = clamp_dates(s0, s1)\n",
    "        s0 = max(s0, WINDOW_START)\n",
    "        if s0 >= s1:\n",
    "            return pd.Series(dtype='float64'), {}\n",
    "        segments = []\n",
    "        counts_by_year = {}\n",
    "        rebal_dates = gen_rebal_dates(s0, s1)\n",
    "        for i in range(len(rebal_dates) - 1):\n",
    "            r0, r1 = rebal_dates[i], rebal_dates[i+1]\n",
    "            cohort = get_allowed_activos_at(r0, selected_filters or [])\n",
    "            if not cohort:\n",
    "                continue\n",
    "            # mantém apenas fundos com dados no segmento\n",
    "            if metric == 'ret':\n",
    "                cols = [c for c in cohort if not df_ret_full[c].loc[r0:r1].dropna().empty]\n",
    "            elif metric == 'vol':\n",
    "                cols = [c for c in cohort if not df_vol_full[c].loc[r0:r1].dropna().empty]\n",
    "            else:\n",
    "                cols = [c for c in cohort if not sharpe_full[c].loc[r0:r1].dropna().empty]\n",
    "            if not cols:\n",
    "                continue\n",
    "            counts_by_year[r0.year] = len(cols)\n",
    "            s = _ind_xs_series(metric, cols).loc[r0:r1]\n",
    "            if not s.empty:\n",
    "                segments.append(s)\n",
    "        if not segments:\n",
    "            return pd.Series(dtype='float64'), counts_by_year\n",
    "        s = pd.concat(segments).sort_index()\n",
    "        if metric == 'ret':\n",
    "            s = (1 + s).cumprod()\n",
    "            s = (s / s.iloc[0]) * 100.0\n",
    "        return s, counts_by_year\n",
    "\n",
    "    def static_cohort_counts(s0, s1):\n",
    "        \"\"\"Contagem anual (30/06→30/06) para TODOS os fundos, sem filtros.\"\"\"\n",
    "        s0, s1 = clamp_dates(s0, s1)\n",
    "        s0 = max(s0, WINDOW_START)\n",
    "        rebal_dates = gen_rebal_dates(s0, s1)\n",
    "        counts = {}\n",
    "        for i in range(len(rebal_dates) - 1):\n",
    "            r0, r1 = rebal_dates[i], rebal_dates[i+1]\n",
    "            # fundos com QUALQUER dado de preço/retorno no segmento\n",
    "            cols = [c for c in funds if not df_ret_full[c].loc[r0:r1].dropna().empty]\n",
    "            if cols:\n",
    "                counts[r0.year] = len(cols)\n",
    "        return counts\n",
    "\n",
    "    # ======================\n",
    "    # RETORNO — Indústria (MEG rebalanced) + Estática (original com clamp)\n",
    "    # ======================\n",
    "    # MEG\n",
    "    if meg_active:\n",
    "        ret_slice, counts_meg = industry_meg_rebalanced('ret', RANGE_START, RANGE_END)\n",
    "    else:\n",
    "        df_ret_meg = df_ret_full[ativos].loc[sd:ed].dropna(how='all')\n",
    "        if not df_ret_meg.empty:\n",
    "            ret_cs_meg     = robust_cross_section_mean(df_ret_meg)\n",
    "            ret_smooth_meg = ret_cs_meg.rolling(ROLL_MM, min_periods=1).mean().dropna()\n",
    "            ret_slice      = base100_from(((1 + ret_smooth_meg).cumprod()).dropna())\n",
    "        else:\n",
    "            ret_slice = pd.Series(dtype='float64')\n",
    "\n",
    "    # Estática (todos os fundos), só quando MEG está ativo — mantém método, mas com datas “clampadas”\n",
    "    if meg_active:\n",
    "        s0, s1 = clamp_dates(sd, ed)\n",
    "        df_ret_all = df_ret_full[funds].loc[s0:s1].dropna(how='all')\n",
    "        if not df_ret_all.empty:\n",
    "            ret_cs_all     = robust_cross_section_mean(df_ret_all)\n",
    "            ret_smooth_all = ret_cs_all.rolling(ROLL_MM, min_periods=1).mean().dropna()\n",
    "            ret_slice_all  = base100_from(((1 + ret_smooth_all).cumprod()).dropna())\n",
    "        else:\n",
    "            ret_slice_all = pd.Series(dtype='float64')\n",
    "    else:\n",
    "        ret_slice_all = pd.Series(dtype='float64')  # evita duplicar\n",
    "\n",
    "    fig_ret = go.Figure()\n",
    "    added = False\n",
    "    if not ret_slice.empty:\n",
    "        fig_ret.add_trace(go.Scatter(\n",
    "            x=ret_slice.index, y=ret_slice.values, mode='lines',\n",
    "            name='Indústria (MEG)' if meg_active else 'Indústria (todos)',\n",
    "            line=dict(width=3)\n",
    "        ))\n",
    "        added = True\n",
    "    if not ret_slice_all.empty:\n",
    "        fig_ret.add_trace(go.Scatter(\n",
    "            x=ret_slice_all.index, y=ret_slice_all.values, mode='lines',\n",
    "            name='Indústria (estática — sem MEG)',\n",
    "            line=dict(dash='dash', width=2)\n",
    "        ))\n",
    "        added = True\n",
    "    if not added:\n",
    "        fig_ret = _annot_fig('Retorno Médio da Indústria (Base 100)',\n",
    "                             'Sem dados válidos no período/filtros. Amplie o intervalo ou remova filtros MEG.')\n",
    "    else:\n",
    "        fig_ret.update_layout(title='Retorno Médio da Indústria (Base 100)',\n",
    "                              xaxis_title='Data', yaxis_title='Índice (Base 100)', template='plotly_white')\n",
    "        fig_ret.update_yaxes(tickformat='.2f')\n",
    "\n",
    "    # ======================\n",
    "    # VOL — Indústria (MEG rebalanced) + Estática (original com clamp)\n",
    "    # ======================\n",
    "    if meg_active:\n",
    "        vol_cs_meg, _ = industry_meg_rebalanced('vol', RANGE_START, RANGE_END)\n",
    "    else:\n",
    "        df_vol_meg = df_vol_full[ativos].loc[sd:ed].dropna(how='all')\n",
    "        if not df_vol_meg.empty:\n",
    "            vol_cs_meg = df_vol_meg.apply(trim_mean_series, axis=1).rolling(ROLL_MM, min_periods=1).mean().dropna()\n",
    "        else:\n",
    "            vol_cs_meg = pd.Series(dtype='float64')\n",
    "\n",
    "    if meg_active:\n",
    "        s0, s1 = clamp_dates(sd, ed)\n",
    "        df_vol_all = df_vol_full[funds].loc[s0:s1].dropna(how='all')\n",
    "        if not df_vol_all.empty:\n",
    "            vol_cs_all = df_vol_all.apply(trim_mean_series, axis=1).rolling(ROLL_MM, min_periods=1).mean().dropna()\n",
    "        else:\n",
    "            vol_cs_all = pd.Series(dtype='float64')\n",
    "    else:\n",
    "        vol_cs_all = pd.Series(dtype='float64')\n",
    "\n",
    "    fig_vol = go.Figure()\n",
    "    added = False\n",
    "    if not vol_cs_meg.empty:\n",
    "        fig_vol.add_trace(go.Scatter(\n",
    "            x=vol_cs_meg.index, y=vol_cs_meg.values, mode='lines',\n",
    "            name='Indústria (MEG)' if meg_active else 'Indústria (todos)',\n",
    "            line=dict(width=3)\n",
    "        ))\n",
    "        added = True\n",
    "    if not vol_cs_all.empty:\n",
    "        fig_vol.add_trace(go.Scatter(\n",
    "            x=vol_cs_all.index, y=vol_cs_all.values, mode='lines',\n",
    "            name='Indústria (estática — sem MEG)', line=dict(dash='dash', width=2)\n",
    "        ))\n",
    "        added = True\n",
    "    if not added:\n",
    "        fig_vol = _annot_fig('Volatilidade Média da Indústria',\n",
    "                             'Sem dados válidos (intervalo muito curto?). Tente ≥ 6 meses por causa do MINP=126.')\n",
    "    else:\n",
    "        fig_vol.update_layout(title='Volatilidade Média da Indústria',\n",
    "                              xaxis_title='Data', yaxis_title='Volatilidade (%)', template='plotly_white')\n",
    "        fig_vol.update_yaxes(tickformat='.2f')\n",
    "\n",
    "    # ======================\n",
    "    # SHARPE — Indústria (MEG rebalanced) + Estática (original com clamp)\n",
    "    # ======================\n",
    "    if meg_active:\n",
    "        sh_cs_meg, _ = industry_meg_rebalanced('sharpe', RANGE_START, RANGE_END)\n",
    "    else:\n",
    "        df_sh_meg = sharpe_full[ativos].loc[sd:ed].dropna(how='all')\n",
    "        if not df_sh_meg.empty:\n",
    "            sh_cs_meg = df_sh_meg.apply(trim_mean_series, axis=1).rolling(ROLL_MM, min_periods=1).mean().dropna()\n",
    "        else:\n",
    "            sh_cs_meg = pd.Series(dtype='float64')\n",
    "\n",
    "    if meg_active:\n",
    "        s0, s1 = clamp_dates(sd, ed)\n",
    "        df_sh_all = sharpe_full[funds].loc[s0:s1].dropna(how='all')\n",
    "        if not df_sh_all.empty:\n",
    "            sh_cs_all = df_sh_all.apply(trim_mean_series, axis=1).rolling(ROLL_MM, min_periods=1).mean().dropna()\n",
    "        else:\n",
    "            sh_cs_all = pd.Series(dtype='float64')\n",
    "    else:\n",
    "        sh_cs_all = pd.Series(dtype='float64')\n",
    "\n",
    "    fig_sh = go.Figure()\n",
    "    added = False\n",
    "    if not sh_cs_meg.empty:\n",
    "        fig_sh.add_trace(go.Scatter(\n",
    "            x=sh_cs_meg.index, y=sh_cs_meg.values, mode='lines',\n",
    "            name='Indústria (MEG)' if meg_active else 'Indústria (todos)',\n",
    "            line=dict(width=3)\n",
    "        ))\n",
    "        added = True\n",
    "    if not sh_cs_all.empty:\n",
    "        fig_sh.add_trace(go.Scatter(\n",
    "            x=sh_cs_all.index, y=sh_cs_all.values, mode='lines',\n",
    "            name='Indústria (estática — sem MEG)', line=dict(dash='dash', width=2)\n",
    "        ))\n",
    "        added = True\n",
    "    if not added:\n",
    "        fig_sh = _annot_fig('Sharpe Médio da Indústria',\n",
    "                            'Sem dados válidos no período. Ajuste datas/filtros.')\n",
    "    else:\n",
    "        fig_sh.update_layout(title='Sharpe Médio da Indústria',\n",
    "                             xaxis_title='Data', yaxis_title='Sharpe', template='plotly_white')\n",
    "        fig_sh.update_yaxes(tickformat='.2f')\n",
    "\n",
    "    # ======================\n",
    "    # Nº de fundos por ano — agora por COHORT anual 30/06→30/06\n",
    "    # ======================\n",
    "    if meg_active:\n",
    "        counts = counts_meg if 'counts_meg' in locals() else {}\n",
    "        if not counts:\n",
    "            # fallback: mostra todos (cohort anual sem filtros) para não ficar vazio\n",
    "            counts = static_cohort_counts(RANGE_START, RANGE_END)\n",
    "        anos = list(range(max(2021, RANGE_START.year), RANGE_END.year + 1))\n",
    "        serie_counts = pd.Series(counts).reindex(anos).fillna(method='ffill').fillna(0).astype(int)\n",
    "        fig_ativ = go.Figure(go.Scatter(\n",
    "            x=serie_counts.index, y=serie_counts.values,\n",
    "            mode='markers+lines', name='Nº de Fundos (cohort anual)'\n",
    "        ))\n",
    "        fig_ativ.update_layout(\n",
    "            title='Evolução Anual do Nº de FI Multimercado (cohort 30/06→30/06)',\n",
    "            xaxis_title='Ano', yaxis_title='Número de Fundos',\n",
    "            template='plotly_white'\n",
    "        )\n",
    "    else:\n",
    "        # Sem MEG: cohort anual para TODOS os fundos\n",
    "        counts_all = static_cohort_counts(RANGE_START, RANGE_END)\n",
    "        anos = list(range(max(2021, RANGE_START.year), RANGE_END.year + 1))\n",
    "        serie_counts = pd.Series(counts_all).reindex(anos).fillna(method='ffill').fillna(0).astype(int)\n",
    "        fig_ativ = go.Figure(go.Scatter(\n",
    "            x=serie_counts.index, y=serie_counts.values,\n",
    "            mode='markers+lines', name='Nº de Fundos (todos — cohort anual)'\n",
    "        ))\n",
    "        fig_ativ.update_layout(\n",
    "            title='Evolução Anual do Nº de FI Multimercado (todos — cohort 30/06→30/06)',\n",
    "            xaxis_title='Ano', yaxis_title='Número de Fundos',\n",
    "            template='plotly_white'\n",
    "        )\n",
    "\n",
    "    return fig_ret, fig_vol, fig_sh, fig_ativ\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# --- opções do dropdown \"ind-funds-compare\" sensíveis ao MEG ---\n",
    "from dash.dependencies import Input, Output, State\n",
    "\n",
    "# ======================\n",
    "# CALLBACK: COMPARAÇÃO (MEG = rebalanced 48m | estática dos fundos não muda)\n",
    "# ======================\n",
    "@app.callback(\n",
    "    Output('ind-comp-chart', 'figure'),\n",
    "    Input('ind-date-picker', 'start_date'),\n",
    "    Input('ind-date-picker', 'end_date'),\n",
    "    Input('meg-filters', 'value'),\n",
    "    Input('ind-metrics-selector', 'value'),   # 'ret' | 'vol' | 'sharpe'\n",
    "    Input('ind-funds-compare', 'value')       # lista de códigos\n",
    ")\n",
    "def update_industry_comparison(start_date, end_date, selected_filters, selected_metric, selected_funds):\n",
    "    sd = pd.to_datetime(start_date); ed = pd.to_datetime(end_date)\n",
    "\n",
    "    WINDOW48_START = pd.Timestamp(\"2021-06-30\")\n",
    "    WINDOW48_END   = pd.Timestamp(\"2025-06-30\")\n",
    "    REBAL_DATES    = pd.to_datetime([\"2021-06-30\",\"2022-06-30\",\"2023-06-30\",\"2024-06-30\",\"2025-06-30\"])\n",
    "\n",
    "    def get_allowed_activos_at(ref_date, filters):\n",
    "        d = df_all.copy()\n",
    "        filters = filters or []\n",
    "        for f in filters:\n",
    "            if f == 'patrimonio':\n",
    "                d = d[d['Patrimônio|||em milhares'] > 300_000]\n",
    "            elif f == 'atuacao':\n",
    "                cutoff = ref_date - pd.DateOffset(years=ANOS_ATUACAO_MIN)\n",
    "                d = d[d['Data do|Início da Série'] <= cutoff]\n",
    "            elif f == 'cotistas':\n",
    "                d = d[d['Média de|Cotistas|1 mês|em unidades'] > 100]\n",
    "            elif f == 'multigestor':\n",
    "                d = d[~d['Multigestor'].isin(['Multigestor', 'Espelho'])]\n",
    "            elif f == 'exclusivo':\n",
    "                d = d[d['Fundo|exclusivo'] != 'Sim']\n",
    "            elif f == 'condominio':\n",
    "                d = d[d['Forma de|condomínio'] != 'Fechado']\n",
    "            elif f == 'exterior':\n",
    "                d = d[~d['Investimento|no Exterior'].isin(['', 'Até 100%'])]\n",
    "            elif f == 'restrito':\n",
    "                d = d[d['Restrito'] != 'Sim']\n",
    "            elif f == 'ihfa':\n",
    "                d = d[d['Gestora com histórico IHFA'] == 'SIM']\n",
    "        ativos = d['Ativo'].unique().tolist()\n",
    "        return [a for a in ativos if a in df_p.columns]\n",
    "\n",
    "    def _ind_xs_series(metric, cols):\n",
    "        if not cols:\n",
    "            return pd.Series(dtype='float64')\n",
    "        if metric == 'ret':\n",
    "            arr = df_ret_full[cols]; xs = robust_cross_section_mean(arr)\n",
    "        elif metric == 'vol':\n",
    "            arr = df_vol_full[cols]; xs = arr.apply(trim_mean_series, axis=1)\n",
    "        else:\n",
    "            arr = sharpe_full[cols]; xs = arr.apply(trim_mean_series, axis=1)\n",
    "        return xs.rolling(ROLL_MM, min_periods=1).mean().dropna()\n",
    "\n",
    "    def industry_rebalanced_series(metric, filters, s0, s1):\n",
    "        s0 = max(pd.to_datetime(s0), WINDOW48_START)\n",
    "        s1 = min(pd.to_datetime(s1), WINDOW48_END)\n",
    "        if s0 >= s1:\n",
    "            return pd.Series(dtype='float64'), {}, s0, s1\n",
    "\n",
    "        segs = []\n",
    "        for i in range(len(REBAL_DATES) - 1):\n",
    "            r0, r1 = REBAL_DATES[i], REBAL_DATES[i+1]\n",
    "            seg_start, seg_end = max(s0, r0), min(s1, r1)\n",
    "            if seg_start >= seg_end:\n",
    "                continue\n",
    "            cohort = get_allowed_activos_at(r0, filters)\n",
    "\n",
    "            if metric == 'ret':\n",
    "                cols = [c for c in cohort if not df_ret_full[c].loc[seg_start:seg_end].dropna().empty]\n",
    "            elif metric == 'vol':\n",
    "                cols = [c for c in cohort if not df_vol_full[c].loc[seg_start:seg_end].dropna().empty]\n",
    "            else:\n",
    "                cols = [c for c in cohort if not sharpe_full[c].loc[seg_start:seg_end].dropna().empty]\n",
    "            if not cols:\n",
    "                continue\n",
    "\n",
    "            s = _ind_xs_series(metric, cols).loc[seg_start:seg_end]\n",
    "            if not s.empty:\n",
    "                segs.append(s)\n",
    "\n",
    "        if not segs:\n",
    "            return pd.Series(dtype='float64'), {}, s0, s1\n",
    "\n",
    "        out = pd.concat(segs).sort_index()\n",
    "        if metric == 'ret':\n",
    "            out = (1 + out).cumprod()\n",
    "            out = (out / out.iloc[0]) * 100.0\n",
    "        return out, {}, s0, s1\n",
    "\n",
    "    metric_key = 'ret' if selected_metric == 'ret' else ('vol' if selected_metric == 'vol' else 'sharpe')\n",
    "\n",
    "    if selected_filters:\n",
    "        ind_series, _, rsd, red = industry_rebalanced_series(metric_key, selected_filters, sd, ed)\n",
    "        if ind_series.empty:\n",
    "            title = {\"ret\":\"Média da Indústria — Retorno (Base 100)\",\n",
    "                     \"vol\":\"Média da Indústria — Volatilidade\",\n",
    "                     \"sharpe\":\"Média da Indústria — Sharpe\"}[selected_metric]\n",
    "            return _empty_fig(title, \"Sem dados disponíveis no período/filtros.\")\n",
    "    else:\n",
    "        # sem filtros → média original de TODOS (como antes)\n",
    "        rsd, red = sd, ed\n",
    "        if metric_key == 'ret':\n",
    "            df_ret = df_ret_full[funds].loc[rsd:red]\n",
    "            if df_ret.empty:\n",
    "                return _empty_fig(\"Média da Indústria — Retorno (Base 100)\", \"Sem dados disponíveis no período.\")\n",
    "            ret_cs = robust_cross_section_mean(df_ret)\n",
    "            ind_series = (1 + ret_cs.rolling(ROLL_MM, min_periods=1).mean()).cumprod().dropna()\n",
    "            ind_series = start_at_first_valid(ind_series)\n",
    "            ind_series = (ind_series / ind_series.iloc[0]) * 100\n",
    "        elif metric_key == 'vol':\n",
    "            df_vol = df_vol_full[funds].loc[rsd:red]\n",
    "            if df_vol.empty:\n",
    "                return _empty_fig(\"Média da Indústria — Volatilidade\", \"Sem dados disponíveis no período.\")\n",
    "            ind_series = df_vol.apply(trim_mean_series, axis=1).rolling(ROLL_MM, min_periods=1).mean().dropna()\n",
    "        else:\n",
    "            df_sh = sharpe_full[funds].loc[rsd:red]\n",
    "            if df_sh.empty:\n",
    "                return _empty_fig(\"Média da Indústria — Sharpe\", \"Sem dados disponíveis no período.\")\n",
    "            ind_series = df_sh.apply(trim_mean_series, axis=1).rolling(ROLL_MM, min_periods=1).mean().dropna()\n",
    "\n",
    "    y_title = {'ret':'Retorno (Base 100)', 'vol':'Volatilidade (%)', 'sharpe':'Sharpe'}[selected_metric]\n",
    "    metric_label = y_title\n",
    "\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=ind_series.index, y=ind_series.values, mode='lines',\n",
    "        name='Média da Indústria' if not selected_filters else 'Média da Indústria (rebal anual)',\n",
    "        line=dict(width=3)\n",
    "    ))\n",
    "\n",
    "    # Sobreposição dos fundos escolhidos (sem alterar o cálculo dos fundos)\n",
    "    ativos_validos = get_allowed_activos(selected_filters or [])\n",
    "    sel = [f for f in (selected_funds or [])\n",
    "           if (selected_filters and f in ativos_validos) or (not selected_filters and f in funds)]\n",
    "\n",
    "    for f in sel:\n",
    "        if selected_metric == 'ret':\n",
    "            s = (1 + df_ret_full[f].loc[rsd:red].fillna(0.0)).cumprod().dropna()\n",
    "            if s.empty:\n",
    "                continue\n",
    "            s = start_at_first_valid(s)\n",
    "            s = (s / s.iloc[0]) * 100\n",
    "        elif selected_metric == 'vol':\n",
    "            s = df_vol_full[f].loc[rsd:red].rolling(ROLL_MM, min_periods=1).mean().dropna()\n",
    "        else:\n",
    "            s = sharpe_full[f].loc[rsd:red].rolling(ROLL_MM, min_periods=1).mean().dropna()\n",
    "        if not s.empty:\n",
    "            fig.add_trace(go.Scatter(x=s.index, y=s.values, mode='lines', name=mapping.get(f, f), opacity=0.9))\n",
    "\n",
    "    ttl_suffix = (f\" — Rebalanceamento anual • 48m: {WINDOW48_START.date()} → {WINDOW48_END.date()}\"\n",
    "                  if selected_filters else \"\")\n",
    "    fig.update_layout(\n",
    "        title=f\"Média da Indústria — {metric_label}{ttl_suffix}\",\n",
    "        template='plotly_white', height=450, xaxis_title='Data'\n",
    "    )\n",
    "    fig.update_yaxes(title_text=y_title, tickformat='.2f')\n",
    "    return fig\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@app.callback(\n",
    "    Output('macro-corr-heatmap', 'figure'),\n",
    "    Output('ls-corr-heatmap',    'figure'),\n",
    "    Input('corr-date-picker',    'start_date'),\n",
    "    Input('corr-date-picker',    'end_date')\n",
    ")\n",
    "def update_corr_heatmaps(start_date, end_date):\n",
    "    sd = pd.to_datetime(start_date)\n",
    "    ed = pd.to_datetime(end_date)\n",
    "    df = df_ret_full.loc[sd:ed]\n",
    "\n",
    "    # 1) Matriz de correlação\n",
    "    macro_corr = df[macro_cols].corr()\n",
    "    ls_corr    = df[ls_cols].corr()\n",
    "\n",
    "    # 2) Heatmap Macro\n",
    "    fig_macro = go.Figure(go.Heatmap(\n",
    "        z=macro_corr.values,\n",
    "        x=macro_labels,\n",
    "        y=macro_labels,\n",
    "        colorscale='Viridis', zmin=-1, zmax=1,\n",
    "        colorbar=dict(title='ρ')\n",
    "    ))\n",
    "    # Anotações\n",
    "    for i, row in enumerate(macro_corr.values):\n",
    "        for j, val in enumerate(row):\n",
    "            fig_macro.add_annotation(\n",
    "                x=macro_labels[j], y=macro_labels[i],\n",
    "                text=f\"{val:.2f}\", showarrow=False,\n",
    "                font=dict(color='white' if abs(val) > 0.5 else 'black')\n",
    "            )\n",
    "    # Ajuste de largura baseado no número de fundos\n",
    "    n = len(macro_cols)\n",
    "    fig_macro.update_layout(\n",
    "        title='Correlação — Macro',\n",
    "        xaxis_tickangle=-45,\n",
    "        margin=dict(t=60, b=100),\n",
    "        width=70 * n,     # 70px por célula\n",
    "        height=70 * n     # idem para altura, deixe quadrado\n",
    "    )\n",
    "\n",
    "    # 3) Heatmap Long/Short\n",
    "    fig_ls = go.Figure(go.Heatmap(\n",
    "        z=ls_corr.values,\n",
    "        x=ls_labels,\n",
    "        y=ls_labels,\n",
    "        colorscale='Viridis', zmin=-1, zmax=1,\n",
    "        colorbar=dict(title='ρ')\n",
    "    ))\n",
    "    for i, row in enumerate(ls_corr.values):\n",
    "        for j, val in enumerate(row):\n",
    "            fig_ls.add_annotation(\n",
    "                x=ls_labels[j], y=ls_labels[i],\n",
    "                text=f\"{val:.2f}\", showarrow=False,\n",
    "                font=dict(color='white' if abs(val) > 0.5 else 'black')\n",
    "            )\n",
    "    fig_ls.update_layout(\n",
    "        title='Correlação — Long/Short',\n",
    "        xaxis_tickangle=-45,\n",
    "        margin=dict(t=60, b=100),\n",
    "        height=500\n",
    "    )\n",
    "\n",
    "    return fig_macro, fig_ls\n",
    "\n",
    "\n",
    "\n",
    "# Sincroniza o dropdown de comparação com os filtros do MEG\n",
    "@app.callback(\n",
    "    Output('ind-funds-compare', 'options'),\n",
    "    Output('ind-funds-compare', 'value'),\n",
    "    Input('meg-filters', 'value'),\n",
    "    State('ind-funds-compare', 'value')\n",
    ")\n",
    "def sync_ind_funds_compare(selected_filters, current_value):\n",
    "    # universo permitido pelo MEG (se vazio, volta a todos)\n",
    "    ativos = get_allowed_activos(selected_filters or [])\n",
    "\n",
    "    # opções visíveis no dropdown\n",
    "    options = [{'label': mapping.get(a, a), 'value': a} for a in ativos]\n",
    "\n",
    "    # normaliza valor atual → lista\n",
    "    if isinstance(current_value, list):\n",
    "        cur = current_value\n",
    "    elif current_value:\n",
    "        cur = [current_value]\n",
    "    else:\n",
    "        cur = []\n",
    "\n",
    "    # mantém apenas fundos válidos pelo MEG\n",
    "    cur = [c for c in cur if c in ativos]\n",
    "\n",
    "    # se esvaziou, não pré-seleciona nada (deixa o usuário escolher)\n",
    "    return options, cur\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@app.callback(\n",
    "    Output('fund-metric-chart', 'figure'),\n",
    "    Input('fund1-dropdown',           'value'),\n",
    "    Input('fund2-dropdown',           'value'),\n",
    "    Input('fund3-dropdown',           'value'),\n",
    "    Input('fund4-dropdown',           'value'),\n",
    "    Input('fund5-dropdown',           'value'),\n",
    "    Input('metric-dropdown',          'value'),\n",
    "    Input('fund-benchmarks-selector', 'value'),\n",
    "    Input('fund-date-picker',         'start_date'),\n",
    "    Input('fund-date-picker',         'end_date'),\n",
    "    Input('meg-filters',              'value'),\n",
    ")\n",
    "def update_fund_chart(f1, f2, f3, f4, f5,\n",
    "                      metrica, benchmarks,\n",
    "                      start_date, end_date, meg_filters):\n",
    "\n",
    "    # 1) converter datas e ativos permitidos\n",
    "    sd = pd.to_datetime(start_date)\n",
    "    ed = pd.to_datetime(end_date)\n",
    "    ativos = get_allowed_activos(meg_filters)\n",
    "\n",
    "    # 2) seleciona até 5 fundos válidos\n",
    "    candidatos = [f1, f2, f3, f4, f5]\n",
    "    selected   = [f for f in candidatos if f in ativos][:5]\n",
    "    nomes      = [mapping[f] for f in selected]\n",
    "    if not selected:\n",
    "        return go.Figure()\n",
    "\n",
    "    # 3) escolhe fonte e função\n",
    "    if metrica == 'retorno':\n",
    "        df_src = df_ret_full\n",
    "\n",
    "        def fn(s):\n",
    "            # acumulação composta diária exata: produto de (1 + retorno)\n",
    "            return (1 + s).cumprod()\n",
    "\n",
    "        y_label, fmt = 'Retorno (Base 100)', 'Retorno Acumulado'\n",
    "    elif metrica == 'volatilidade':\n",
    "        df_src, fn = df_vol_full, lambda s: s.rolling(ROLL_MM, min_periods=1).mean()\n",
    "        y_label, fmt = 'Volatilidade', 'Volatilidade'\n",
    "    else:\n",
    "        df_src, fn = sharpe_full, lambda s: s.rolling(ROLL_MM, min_periods=1).mean()\n",
    "        y_label, fmt = 'Sharpe', 'Sharpe'\n",
    "\n",
    "    # 4) coleta séries de fundos\n",
    "    series = {}\n",
    "    for f, nome in zip(selected, nomes):\n",
    "        s = fn(df_src[f]).dropna().loc[sd:ed]\n",
    "        if not s.empty:\n",
    "            series[nome] = s\n",
    "\n",
    "    # 5) adiciona benchmarks **só se for Retorno**, usando a mesma fn\n",
    "    if metrica == 'retorno':\n",
    "        if 'cdi' in benchmarks:\n",
    "            s_cdi = fn(cdi_idx.pct_change().fillna(0)).loc[sd:ed]\n",
    "            if not s_cdi.empty:\n",
    "                series['CDI (BM)'] = s_cdi\n",
    "        if 'ihfa' in benchmarks:\n",
    "            s_ihfa = fn(ihfa_idx.pct_change().fillna(0)).loc[sd:ed]\n",
    "            if not s_ihfa.empty:\n",
    "                series['IHFA (BM)'] = s_ihfa\n",
    "        if 'atu' in benchmarks:\n",
    "            s_atu = atu_series.loc[sd:ed]\n",
    "            if not s_atu.empty:\n",
    "                series['Meta Atuarial'] = s_atu\n",
    "\n",
    "    # 6) define data comum de início (mais recente entre todas)\n",
    "    datas = [s.index.min() for s in series.values()]\n",
    "    start_common = max(datas)\n",
    "\n",
    "    # 7) trunca e, se for Retorno, rebase em 100\n",
    "    for name, s in list(series.items()):\n",
    "        s2 = s.loc[start_common:ed]\n",
    "        if s2.empty:\n",
    "            series.pop(name)\n",
    "        else:\n",
    "            series[name] = s2.div(s2.iloc[0]).mul(100) if metrica == 'retorno' else s2\n",
    "\n",
    "    # 8) se não sobrou nada, retorna vazio\n",
    "    if not series:\n",
    "        return go.Figure()\n",
    "\n",
    "    # 9) monta figura\n",
    "    fig = go.Figure()\n",
    "    for name, s in series.items():\n",
    "        fig.add_trace(go.Scatter(x=s.index, y=s.values, mode='lines', name=name))\n",
    "\n",
    "    # 10) título dinâmico\n",
    "    title = f\"{fmt} — {' vs '.join(nomes)}\"\n",
    "    if metrica == 'retorno':\n",
    "        if 'cdi'  in benchmarks: title += ' vs CDI'\n",
    "        if 'ihfa' in benchmarks: title += ' vs IHFA'\n",
    "        if 'atu'  in benchmarks: title += ' vs Meta Atuarial'\n",
    "\n",
    "    # 11) layout final\n",
    "    fig.update_layout(\n",
    "        title=title,\n",
    "        xaxis_title='Data',\n",
    "        yaxis_title=y_label,\n",
    "        xaxis=dict(range=[start_common, ed]),\n",
    "        template='plotly_white'\n",
    "    )\n",
    "    fig.update_yaxes(tickformat='.2f')\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "\n",
    "# ======================\n",
    "# CALLBACK: ATUALIZA FUNDOS DISPONÍVEIS\n",
    "# ======================\n",
    "@app.callback(\n",
    "    [\n",
    "        # opções para cada um dos 5 dropdowns\n",
    "        Output('fund1-dropdown', 'options'),\n",
    "        Output('fund2-dropdown', 'options'),\n",
    "        Output('fund3-dropdown', 'options'),\n",
    "        Output('fund4-dropdown', 'options'),\n",
    "        Output('fund5-dropdown', 'options'),\n",
    "        # valor inicial para cada dropdown\n",
    "        Output('fund1-dropdown', 'value'),\n",
    "        Output('fund2-dropdown', 'value'),\n",
    "        Output('fund3-dropdown', 'value'),\n",
    "        Output('fund4-dropdown', 'value'),\n",
    "        Output('fund5-dropdown', 'value'),\n",
    "    ],\n",
    "    Input('meg-filters', 'value')\n",
    ")\n",
    "def update_fund_dropdowns(selected_filters):\n",
    "    # Determina os ativos permitidos pelos filtros\n",
    "    ativos = get_allowed_activos(selected_filters)\n",
    "\n",
    "    # Constrói a lista de opções\n",
    "    options = [{'label': mapping[a], 'value': a} for a in ativos]\n",
    "\n",
    "    # Valor padrão: primeiro ativo em fund1; os demais começam vazios\n",
    "    default1 = ativos[0] if ativos else None\n",
    "\n",
    "    return (\n",
    "        options,  # fund1 opções\n",
    "        options,  # fund2 opções\n",
    "        options,  # fund3 opções\n",
    "        options,  # fund4 opções\n",
    "        options,  # fund5 opções\n",
    "        default1, # fund1 valor\n",
    "        None,     # fund2 valor\n",
    "        None,     # fund3 valor\n",
    "        None,     # fund4 valor\n",
    "        None      # fund5 valor\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from dash.dependencies import Input, Output, State\n",
    "\n",
    "@app.callback(\n",
    "    Output(\"fund-selector\", \"options\"),\n",
    "    Output(\"fund-selector\", \"value\"),\n",
    "    Input(\"meg-filters\", \"value\"),\n",
    "    State(\"fund-selector\", \"value\"),  # usa State pra evitar dependência circular\n",
    ")\n",
    "def sync_fund_selector_with_meg(selected_filters, current_value):\n",
    "    ativos = get_allowed_activos(selected_filters or [])\n",
    "    if not ativos:\n",
    "        ativos = funds\n",
    "\n",
    "    options = [{'label': mapping[a], 'value': a} for a in ativos]\n",
    "\n",
    "    # normaliza o valor atual\n",
    "    if isinstance(current_value, list):\n",
    "        current = current_value\n",
    "    elif current_value:\n",
    "        current = [current_value]\n",
    "    else:\n",
    "        current = []\n",
    "\n",
    "    # mantém só os válidos\n",
    "    filtered = [f for f in current if f in ativos]\n",
    "\n",
    "    # garante dois fundos válidos (mesma lógica de fallback do rolling)\n",
    "    pair = filtered[:2]\n",
    "    if len(pair) < 2:\n",
    "        for a in ativos:\n",
    "            if a not in pair:\n",
    "                pair.append(a)\n",
    "            if len(pair) == 2:\n",
    "                break\n",
    "\n",
    "    if len(pair) == 0:\n",
    "        pair = funds[:2]\n",
    "    elif len(pair) == 1:\n",
    "        other = [f for f in funds if f != pair[0]]\n",
    "        pair = [pair[0], other[0] if other else pair[0]]\n",
    "\n",
    "    return options, pair\n",
    "\n",
    "\n",
    "\n",
    "@app.callback(\n",
    "    Output(\"rolling-corr-graph\", \"figure\"),\n",
    "    [\n",
    "        Input(\"rolling-corr-date-picker\", \"start_date\"),\n",
    "        Input(\"rolling-corr-date-picker\", \"end_date\"),\n",
    "        Input(\"fund-selector\", \"value\"),\n",
    "        Input(\"meg-filters\", \"value\"),  # adicionado\n",
    "    ]\n",
    ")\n",
    "def update_rolling_correlation(start_date, end_date, selected_cols, selected_filters):\n",
    "    # determina ativos válidos pelos filtros MEG (fallback para todos)\n",
    "    ativos = get_allowed_activos(selected_filters or [])\n",
    "    if not ativos:\n",
    "        ativos = funds\n",
    "\n",
    "    # constrói par de fundos válidos\n",
    "    if not selected_cols:\n",
    "        pair = ativos[:2]\n",
    "    else:\n",
    "        sel = selected_cols if isinstance(selected_cols, list) else [selected_cols]\n",
    "        filtered = [f for f in sel if f in ativos]\n",
    "        if len(filtered) >= 2:\n",
    "            pair = filtered[:2]\n",
    "        else:\n",
    "            needed = 2 - len(filtered)\n",
    "            addition = [f for f in ativos if f not in filtered][:needed]\n",
    "            pair = filtered + addition\n",
    "            if len(pair) < 2:\n",
    "                extra = [f for f in funds if f not in pair][: (2 - len(pair))]\n",
    "                pair = pair + extra\n",
    "\n",
    "    # garantir exatamente dois fundos\n",
    "    if len(pair) == 0:\n",
    "        pair = funds[:2]\n",
    "    elif len(pair) == 1:\n",
    "        other = [f for f in funds if f != pair[0]]\n",
    "        pair = [pair[0], other[0] if other else pair[0]]\n",
    "\n",
    "    f1, f2 = pair[0], pair[1]\n",
    "\n",
    "    # slice por data\n",
    "    sd = pd.to_datetime(start_date)\n",
    "    ed = pd.to_datetime(end_date)\n",
    "    df_pair = df_ret_full.loc[sd:ed, [f1, f2]].dropna()\n",
    "\n",
    "    if df_pair.empty:\n",
    "        return go.Figure()  # sem dados válidos\n",
    "\n",
    "    fig = go.Figure()\n",
    "    for w in [252, 504, 756]:\n",
    "        corr = df_pair[f1].rolling(window=w).corr(df_pair[f2])\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=corr.index,\n",
    "            y=corr,\n",
    "            mode=\"lines\",\n",
    "            name=f\"Janela {w} dias\"\n",
    "        ))\n",
    "\n",
    "    fig.add_hline(y=0, line_dash=\"dash\", line_color=\"black\")\n",
    "\n",
    "    labels = {c: mapping.get(c, c) for c in (f1, f2)}\n",
    "    fig.update_layout(\n",
    "        title=(\n",
    "            f\"Correlação Rolling entre<br>\"\n",
    "            f\"{labels[f1]} e {labels[f2]}\"\n",
    "        ),\n",
    "        xaxis_title=\"Data\",\n",
    "        yaxis_title=\"Correlação (ρ)\",\n",
    "        template=\"plotly_white\",\n",
    "        height=500,\n",
    "        margin={\"l\": 40, \"r\": 20, \"t\": 80, \"b\": 40}\n",
    "    )\n",
    "    fig.update_yaxes(tickformat='.2f')\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "\n",
    "# Sincroniza as opções do \"Destaque\" com os filtros do MEG\n",
    "@app.callback(\n",
    "    Output('corrpl-highlight', 'options'),\n",
    "    Output('corrpl-highlight', 'value'),\n",
    "    Input('meg-filters', 'value'),\n",
    "    State('corrpl-highlight', 'value')\n",
    ")\n",
    "def sync_corrpl_controls(meg_filters, current_focus):\n",
    "    ativos = get_allowed_activos(meg_filters or [])\n",
    "    codes = macro_codes + ls_codes\n",
    "    allowed = [c for c in ativos if any(c.startswith(code) for code in codes)]\n",
    "    opts = [{'label': f\"{mapping.get(c,c)} ({c})\", 'value': c} for c in allowed]\n",
    "    focus = current_focus if current_focus in allowed else None\n",
    "    return opts, focus\n",
    "\n",
    "\n",
    "# Figura PL × Volatilidade (cor = média de correlação)\n",
    "@app.callback(\n",
    "    Output('corrpl-scatter', 'figure'),\n",
    "    Input('corrpl-date-picker', 'start_date'),\n",
    "    Input('corrpl-date-picker', 'end_date'),\n",
    "    Input('meg-filters',        'value'),\n",
    "    Input('corrpl-group',       'value'),   # 'all' | 'macro' | 'ls'\n",
    "    Input('corrpl-highlight',   'value')\n",
    ")\n",
    "def update_corrpl_scatter(start_date, end_date, meg_filters, group_sel, focus_code):\n",
    "    sd, ed = pd.to_datetime(start_date), pd.to_datetime(end_date)\n",
    "    base_codes = macro_codes + ls_codes\n",
    "    ativos_allowed = get_allowed_activos(meg_filters or [])\n",
    "    cols_all = [c for c in df_ret_full.columns\n",
    "                if any(c.startswith(code) for code in base_codes) and c in ativos_allowed]\n",
    "\n",
    "    if not cols_all:\n",
    "        return _empty_fig(f'PL × Volatilidade (cor = ρ) — {sd.date()} a {ed.date()}',\n",
    "                          \"Nenhum fundo atende aos filtros MEG.\")\n",
    "\n",
    "    def is_macro(c): return any(c.startswith(code) for code in macro_codes)\n",
    "    def is_ls(c):    return any(c.startswith(code) for code in ls_codes)\n",
    "    if group_sel == 'macro':\n",
    "        cols = [c for c in cols_all if is_macro(c)]\n",
    "    elif group_sel == 'ls':\n",
    "        cols = [c for c in cols_all if is_ls(c)]\n",
    "    else:\n",
    "        cols = cols_all\n",
    "\n",
    "    if len(cols) < 2:\n",
    "        return _empty_fig(f'PL × Volatilidade (cor = ρ) — {sd.date()} a {ed.date()}',\n",
    "                          \"Selecione pelo menos 2 fundos no grupo/MEG e aumente o período.\")\n",
    "\n",
    "    df_ret = df_ret_full.loc[sd:ed, cols]\n",
    "    if df_ret.dropna(how='all').empty:\n",
    "        return _empty_fig(f'PL × Volatilidade (cor = ρ) — {sd.date()} a {ed.date()}',\n",
    "                          \"Sem retornos no período selecionado.\")\n",
    "\n",
    "    # Correlação média excluindo diagonal\n",
    "    corr = df_ret.corr(min_periods=30)\n",
    "    if corr.shape[0] < 2 or corr.isna().all().all():\n",
    "        return _empty_fig(f'PL × Volatilidade (cor = ρ) — {sd.date()} a {ed.date()}',\n",
    "                          \"Dados insuficientes para correlação (tente ampliar o período).\")\n",
    "    corr.values[np.arange(len(corr)), np.arange(len(corr))] = np.nan\n",
    "    denom = (~corr.isna()).sum(axis=1).replace(0, np.nan)\n",
    "    avg_corr = (corr.sum(axis=1, skipna=True) / denom).replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "    # Vol média (fallback se rolling MINP=126 zerar tudo)\n",
    "    df_vol = df_vol_full.loc[sd:ed, cols]\n",
    "    avg_vol = df_vol.mean()\n",
    "    if avg_vol.isna().all():\n",
    "        avg_vol = (df_ret.std() * (252 ** 0.5) * 100)\n",
    "\n",
    "    # PL\n",
    "    df_pl_port = df_all.set_index('Ativo')['Patrimônio|||em milhares'].astype(float).mul(1_000)\n",
    "\n",
    "    df_plot = (pd.DataFrame({\n",
    "        'Code':       avg_corr.index,\n",
    "        'AvgCorr':    avg_corr.values,\n",
    "        'Volatility': avg_vol.reindex(avg_corr.index).values,\n",
    "        'PL':         df_pl_port.reindex(avg_corr.index).values\n",
    "    }).dropna(subset=['AvgCorr', 'Volatility', 'PL']))\n",
    "\n",
    "    if df_plot.empty:\n",
    "        return _empty_fig(f'PL × Volatilidade (cor = ρ) — {sd.date()} a {ed.date()}',\n",
    "                          \"Sem dados após limpeza (NaNs). Ajuste período/filtros.\")\n",
    "\n",
    "    df_plot['Fund'] = df_plot['Code'].map(mapping).fillna(df_plot['Code'])\n",
    "\n",
    "    fig = px.scatter(\n",
    "        df_plot, x='Volatility', y='PL', size='PL', color='AvgCorr',\n",
    "        hover_name='Fund',\n",
    "        hover_data={'Code': True, 'Volatility': ':.2f', 'PL': ':,.0f', 'AvgCorr': ':.2f'},\n",
    "        size_max=90, labels={'Volatility':'Volatilidade (%)','PL':'Patrimônio Líquido (R$)','AvgCorr':'Média de ρ'},\n",
    "        title=f'PL × Volatilidade (cor = Correlação Média) — {sd.date()} a {ed.date()}',\n",
    "        template='plotly_white', color_continuous_scale='Viridis', range_color=(-1, 1)\n",
    "    )\n",
    "    fig.update_traces(marker=dict(line=dict(width=1, color='black'), sizemin=10))\n",
    "    fig.update_coloraxes(showscale=True, cmin=-1, cmax=1, colorbar=dict(title='ρ'))\n",
    "    fig.update_layout(margin=dict(r=120, t=60, l=40, b=40))\n",
    "\n",
    "    if focus_code in set(df_plot['Code']):\n",
    "        row = df_plot[df_plot['Code'] == focus_code].iloc[0]\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=[row['Volatility']], y=[row['PL']], mode='markers+text',\n",
    "            text=[f\"★ {row['Fund']}\"], textposition='top center',\n",
    "            name=f\"Destaque: {row['Fund']}\",\n",
    "            marker=dict(size=18, symbol='circle-open-dot', line=dict(width=2, color='black'),\n",
    "                        color='rgba(0,0,0,0)'), showlegend=False\n",
    "        ))\n",
    "    return fig\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@app.callback(\n",
    "    Output(\"bubble3d\", \"figure\"),\n",
    "    Input(\"bubble-date-picker\", \"start_date\"),\n",
    "    Input(\"bubble-date-picker\", \"end_date\"),\n",
    "    Input(\"bubble-funds-select\", \"value\"),\n",
    ")\n",
    "def update_bubble3d(start_date, end_date, sel_codes):\n",
    "    if not sel_codes:\n",
    "        return _annot_fig('Bubble Chart 3D', 'Selecione ao menos um fundo.')\n",
    "\n",
    "    sd = pd.to_datetime(start_date)\n",
    "    ed = pd.to_datetime(end_date)\n",
    "\n",
    "    df_ret = df_ret_full.reindex(columns=sel_codes).loc[sd:ed]\n",
    "    df_vol = df_vol_full.reindex(columns=sel_codes).loc[sd:ed]\n",
    "\n",
    "    if df_ret.dropna(how='all').empty:\n",
    "        return _annot_fig('Bubble Chart 3D', 'Nenhum dado disponível neste período.')\n",
    "\n",
    "    # Correlação média por fundo (exclui a diagonal). Fallback = 0.0\n",
    "    corr = df_ret.corr(min_periods=30)\n",
    "    if corr.shape[0] > 0:\n",
    "        corr = corr.copy()\n",
    "        np.fill_diagonal(corr.values, np.nan)\n",
    "        avg_corr = corr.mean(axis=1)\n",
    "    else:\n",
    "        avg_corr = pd.Series(index=sel_codes, dtype='float64')\n",
    "    avg_corr = avg_corr.reindex(sel_codes).fillna(0.0)\n",
    "\n",
    "    # Vol média anualizada; fallback p/ std anualizada caso NaN\n",
    "    avg_vol = df_vol.mean().reindex(sel_codes)\n",
    "    fallback_vol = (df_ret.std() * (252 ** 0.5) * 100).reindex(sel_codes)\n",
    "    avg_vol = avg_vol.fillna(fallback_vol)\n",
    "\n",
    "    # Retorno acumulado Base 100 (robusto a NaN no início)\n",
    "    ret_end = pd.Series(index=sel_codes, dtype='float64')\n",
    "    for code in sel_codes:\n",
    "        s = df_ret[code].dropna()\n",
    "        if s.empty:\n",
    "            continue\n",
    "        cum = (1.0 + s).cumprod()\n",
    "        ret_end[code] = (cum.iloc[-1] / cum.iloc[0]) * 100.0\n",
    "\n",
    "    # Tamanho pela PL (robusto a ruído/NaN)\n",
    "    pl_vals = pd.to_numeric(df_pl.reindex(sel_codes), errors=\"coerce\")\n",
    "    valid_pl = pl_vals.dropna()\n",
    "    max_pl = valid_pl.max() if (not valid_pl.empty and valid_pl.max() > 0) else 1.0\n",
    "    sizes = ((pl_vals.fillna(0.0) / max_pl) * 40.0 + 5.0)\n",
    "\n",
    "    fig = go.Figure()\n",
    "    plotted = 0\n",
    "    for code in sel_codes:\n",
    "        x = float(avg_corr.get(code, np.nan))\n",
    "        y = float(avg_vol.get(code, np.nan))\n",
    "        z = float(ret_end.get(code, np.nan))\n",
    "        if np.isnan(x) or np.isnan(y) or np.isnan(z):\n",
    "            continue\n",
    "        fig.add_trace(go.Scatter3d(\n",
    "            x=[x], y=[y], z=[z], mode='markers',\n",
    "            name=mapping.get(code, code),\n",
    "            marker=dict(\n",
    "                size=float(sizes.get(code, 10.0)),\n",
    "                line=dict(width=1, color='black'),\n",
    "                opacity=0.85\n",
    "            )\n",
    "        ))\n",
    "        plotted += 1\n",
    "\n",
    "    if plotted == 0:\n",
    "        return _annot_fig('Bubble Chart 3D', 'Sem pontos após a limpeza. Amplie o período ou selecione outros fundos.')\n",
    "\n",
    "    fig.update_layout(\n",
    "        scene=dict(\n",
    "            xaxis_title=\"Média de Correlação (ρ)\",\n",
    "            yaxis_title=\"Volatilidade (%)\",\n",
    "            zaxis_title=\"Retorno Acumulado (Base 100)\"\n",
    "        ),\n",
    "        template='plotly_white',\n",
    "        title=f\"Período: {sd.date()} → {ed.date()}\",\n",
    "        height=600,\n",
    "        margin=dict(l=0, r=0, t=60, b=0)\n",
    "    )\n",
    "    return fig\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ─── Bloco: Callback para o PCA ───\n",
    "@app.callback(\n",
    "    Output(\"pca-graph\", \"figure\"),\n",
    "    Input(\"pca-fundos\", \"value\"),\n",
    "    Input(\"pca-date-range\", \"start_date\"),\n",
    "    Input(\"pca-date-range\", \"end_date\"),\n",
    ")\n",
    "def update_pca(fund_list, start_date, end_date):\n",
    "    import plotly.express as px\n",
    "\n",
    "    if not fund_list:\n",
    "        return _annot_fig(\"PCA 2D\", \"Selecione ao menos um fundo.\")\n",
    "\n",
    "    sd = pd.to_datetime(start_date)\n",
    "    ed = pd.to_datetime(end_date)\n",
    "\n",
    "    cols = [c for c in fund_list if c in df_ret_full.columns]\n",
    "    if not cols:\n",
    "        return _annot_fig(\"PCA 2D\", \"Fundos inválidos para o período.\")\n",
    "\n",
    "    df_ret = df_ret_full.reindex(columns=cols).loc[sd:ed]\n",
    "    df_vol = df_vol_full.reindex(columns=cols).loc[sd:ed]\n",
    "\n",
    "    if df_ret.dropna(how='all').empty:\n",
    "        return _annot_fig(\"PCA 2D\", \"Nenhum dado disponível neste período.\")\n",
    "\n",
    "    # Métricas robustas\n",
    "    corr = df_ret.corr(min_periods=30)\n",
    "    if corr.shape[0] > 0:\n",
    "        corr = corr.copy()\n",
    "        np.fill_diagonal(corr.values, np.nan)\n",
    "        avg_corr = corr.mean(axis=1)\n",
    "    else:\n",
    "        avg_corr = pd.Series(index=cols, dtype='float64')\n",
    "    avg_corr = avg_corr.reindex(cols).fillna(0.0)\n",
    "\n",
    "    avg_vol  = df_vol.mean().reindex(cols)\n",
    "    fallback_vol = (df_ret.std() * (252 ** 0.5) * 100).reindex(cols)\n",
    "    avg_vol  = avg_vol.fillna(fallback_vol)\n",
    "\n",
    "    # Retorno Base 100 (fim do range), robusto a NaN no início\n",
    "    ret_end = pd.Series(index=cols, dtype='float64')\n",
    "    for code in cols:\n",
    "        s = df_ret[code].dropna()\n",
    "        if s.empty:\n",
    "            continue\n",
    "        cum = (1.0 + s).cumprod()\n",
    "        ret_end[code] = (cum.iloc[-1] / cum.iloc[0]) * 100.0\n",
    "\n",
    "    pl_vals = pd.to_numeric(df_pl.reindex(cols), errors=\"coerce\")\n",
    "\n",
    "    features = (\n",
    "        pd.DataFrame({\n",
    "            'AvgCorr':    avg_corr,\n",
    "            'Volatility': avg_vol,\n",
    "            'RetBase100': ret_end,\n",
    "            'PL':         pl_vals\n",
    "        })\n",
    "        .replace([np.inf, -np.inf], np.nan)\n",
    "        .dropna()\n",
    "    )\n",
    "\n",
    "    if features.shape[0] < 2:\n",
    "        return _annot_fig(\"PCA 2D\", \"Dados insuficientes após limpeza (precisa ≥ 2 fundos).\")\n",
    "\n",
    "    try:\n",
    "        X = features[['AvgCorr', 'Volatility', 'RetBase100']].values\n",
    "        pcs = PCA(n_components=2).fit_transform(X)\n",
    "    except Exception as e:\n",
    "        return _annot_fig(\"PCA 2D\", f\"Erro no PCA: {e}\")\n",
    "\n",
    "    df_pca = pd.DataFrame(pcs, index=features.index, columns=['PC1', 'PC2'])\n",
    "    df_pca['Fund'] = [mapping.get(code, code) for code in df_pca.index]  # ← fixa fillna(Index)\n",
    "    df_pca['PL']   = features['PL'].astype(float)\n",
    "\n",
    "    fig = px.scatter(\n",
    "        df_pca,\n",
    "        x='PC1', y='PC2',\n",
    "        size='PL', color='Fund',\n",
    "        hover_name='Fund',\n",
    "        hover_data={'PL': ':,.0f', 'PC1': ':.2f', 'PC2': ':.2f'},\n",
    "        size_max=60,\n",
    "        template='plotly_white',\n",
    "        title=f\"PCA 2D ({sd.date()} → {ed.date()})\"\n",
    "    )\n",
    "    return fig\n",
    "\n",
    "\n",
    "@app.callback(\n",
    "    Output('dendo-graph', 'figure'),\n",
    "    Input('dendo-vol-range', 'value'),\n",
    "    Input('dendo-funds-select', 'value'),\n",
    ")\n",
    "def update_dendrogram(vol_range, selected_codes):\n",
    "    from plotly.figure_factory import create_dendrogram\n",
    "    from scipy.cluster import hierarchy as sch\n",
    "    from scipy.spatial import distance as ssd\n",
    "\n",
    "    # Helper: garante escala em %\n",
    "    def to_percent(s):\n",
    "        s = pd.Series(s, dtype=\"float64\")\n",
    "        return s * 100.0 if s.max() <= 1.5 else s  # até ~150% assume decimal\n",
    "\n",
    "    vmin, vmax = (vol_range or [0, 60])  # faixas em %\n",
    "    sd = START_FILTER\n",
    "    ed = df_ret_full.index.max()\n",
    "\n",
    "    fund_pool = [\n",
    "        c for c in (selected_codes or [])\n",
    "        if any(c.startswith(code) for code in codes) and c in df_ret_full.columns\n",
    "    ]\n",
    "    if len(fund_pool) < 2:\n",
    "        return go.Figure(layout_title_text=\"Selecione ao menos 2 fundos.\")\n",
    "\n",
    "    # Vol anualizada média no período -> converte para %\n",
    "    vol_mean_raw = df_vol_full.loc[sd:ed, fund_pool].mean().dropna()\n",
    "    vol_mean_pct = to_percent(vol_mean_raw)\n",
    "\n",
    "    # Filtra pela faixa (em %)\n",
    "    eligible = vol_mean_pct[(vol_mean_pct >= vmin) & (vol_mean_pct <= vmax)].index.tolist()\n",
    "    if len(eligible) < 2:\n",
    "        return go.Figure(layout_title_text=\"Faixa de volatilidade muito restrita: selecione ao menos 2 fundos.\")\n",
    "\n",
    "    # Retornos (preenche NaN p/ robustez)\n",
    "    df_ret = df_ret_full.loc[sd:ed, eligible].fillna(0.0)\n",
    "    X = df_ret.T.values  # (n_fundos, n_datas)\n",
    "\n",
    "    # Distância 1 - correlação (fallback euclidiana)\n",
    "    try:\n",
    "        D = ssd.pdist(X, metric='correlation')\n",
    "        Z = sch.linkage(D, method='average')\n",
    "        distfun = lambda x: ssd.pdist(x, 'correlation')\n",
    "    except Exception:\n",
    "        Z = sch.linkage(X, method='average', metric='euclidean')\n",
    "        distfun = lambda x: ssd.pdist(x, 'euclidean')\n",
    "\n",
    "    # Rótulos com nome + vol%\n",
    "    labels = [\n",
    "        f\"{mapping.get(f, f)} — {vol_mean_pct[f]:.2f}%\"\n",
    "        for f in df_ret.columns\n",
    "    ]\n",
    "\n",
    "    fig = create_dendrogram(\n",
    "        X,\n",
    "        labels=labels,\n",
    "        orientation='left',\n",
    "        distfun=distfun,\n",
    "        linkagefun=lambda x: sch.linkage(x, method='average')\n",
    "    )\n",
    "\n",
    "    n = len(eligible)\n",
    "    fig.update_layout(\n",
    "        title=(f\"Dendrograma (distância = 1 − correlação) — \"\n",
    "               f\"Faixa de Vol: {vmin:.1f}% a {vmax:.1f}% | {n} fundos\"),\n",
    "        template='plotly_white',\n",
    "        height=max(300, 30 * n + 200),\n",
    "        margin=dict(l=260, r=20, t=70, b=20)\n",
    "    )\n",
    "    fig.update_xaxes(title_text=\"Distância\")\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "@app.callback(\n",
    "    Output('mortality-chart', 'figure'),\n",
    "    Input('mort-date-picker', 'start_date'),\n",
    "    Input('mort-date-picker', 'end_date'),\n",
    "    Input('mort-fund-select', 'value'),\n",
    ")\n",
    "def update_mortality_norm_with_bubbles(start_date, end_date, fund_values):\n",
    "    # 1) pegar df de vida sem usar \"or\" em DataFrame\n",
    "    life_df = globals().get('df_life_all', None)\n",
    "    if life_df is None:\n",
    "        life_df = globals().get('df_life', None)\n",
    "    if life_df is None or not isinstance(life_df, pd.DataFrame) or life_df.empty:\n",
    "        return _annot_fig('Mortalidade (anual)', 'Planilha inicio_fim.xlsx vazia ou não carregada.')\n",
    "\n",
    "    code_col  = 'CodigoFinal' if 'CodigoFinal' in life_df.columns else 'Codigo'\n",
    "    ini_col   = 'DataInicio'\n",
    "    fim_col   = 'DataFim'\n",
    "\n",
    "    df = life_df.copy()\n",
    "    df[code_col] = df[code_col].astype(str).str.strip()\n",
    "    df[ini_col]  = pd.to_datetime(df[ini_col], errors='coerce')\n",
    "    df[fim_col]  = pd.to_datetime(df[fim_col], errors='coerce')\n",
    "\n",
    "    # 2) intervalo\n",
    "    sd = pd.to_datetime(start_date) if start_date else globals().get('MORT_MIN', pd.Timestamp('2000-01-01'))\n",
    "    ed = pd.to_datetime(end_date)   if end_date   else globals().get('MORT_MAX', pd.Timestamp.today().normalize())\n",
    "    if sd >= ed:\n",
    "        return _annot_fig('Mortalidade (anual)', 'Intervalo de datas inválido.')\n",
    "\n",
    "    years = np.arange(sd.year, ed.year + 1, dtype=int)\n",
    "\n",
    "    # 3) mortes/total por ano (SÓ inicio_fim.xlsx)\n",
    "    deaths, totals = [], []\n",
    "    for y in years:\n",
    "        y0 = pd.Timestamp(y, 1, 1)\n",
    "        y1 = pd.Timestamp(y, 12, 31)\n",
    "\n",
    "        # mortes: códigos distintos com DataFim dentro do ano\n",
    "        d = df.loc[df[fim_col].notna() & (df[fim_col] >= y0) & (df[fim_col] <= y1), code_col].nunique()\n",
    "\n",
    "        # total de fundos vivos em QUALQUER ponto do ano (iniciou até 31/12 e não acabou antes de 01/01)\n",
    "        alive_mask = (df[ini_col].notna()) & (df[ini_col] <= y1) & (df[fim_col].isna() | (df[fim_col] >= y0))\n",
    "        t = df.loc[alive_mask, code_col].nunique()\n",
    "\n",
    "        deaths.append(int(d))\n",
    "        totals.append(int(t))\n",
    "\n",
    "    ratio = np.array([d / t if t > 0 else np.nan for d, t in zip(deaths, totals)], dtype=float)\n",
    "\n",
    "    # 4) figura base (pontos = anos, y = mortes/total)\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=years, y=ratio, mode='markers',\n",
    "        name='Mortes / Total (ano)',\n",
    "        marker=dict(size=9, line=dict(width=1, color='black'), opacity=0.9),\n",
    "        customdata=np.c_[deaths, totals],\n",
    "        hovertemplate='Ano: %{x}<br>Mortes: %{customdata[0]}<br>Total: %{customdata[1]}<br>Taxa: %{y:.4f}<extra></extra>'\n",
    "    ))\n",
    "\n",
    "    # 5) linha de média do período\n",
    "    mean_val = float(np.nanmean(ratio)) if np.isfinite(ratio).any() else np.nan\n",
    "    if np.isfinite(mean_val):\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=years, y=[mean_val] * len(years), mode='lines',\n",
    "            name='Média no período', line=dict(width=3)\n",
    "        ))\n",
    "\n",
    "    # 6) bolhas de INÍCIO e FIM para os fundos selecionados (multi)\n",
    "    if isinstance(fund_values, list):\n",
    "        selected = [str(v) for v in fund_values]\n",
    "    elif fund_values:\n",
    "        selected = [str(fund_values)]\n",
    "    else:\n",
    "        selected = []\n",
    "\n",
    "    if selected:\n",
    "        ratio_by_year = {int(y): r for y, r in zip(years, ratio)}\n",
    "\n",
    "        # INÍCIO\n",
    "        xs_i, ys_i, labels_i = [], [], []\n",
    "        # FIM\n",
    "        xs_f, ys_f, labels_f = [], [], []\n",
    "\n",
    "        for code in selected:\n",
    "            rows = df.loc[df[code_col].astype(str) == code]\n",
    "            if rows.empty:\n",
    "                continue\n",
    "\n",
    "            di = rows[ini_col].dropna()\n",
    "            dfim = rows[fim_col].dropna()\n",
    "\n",
    "            if not di.empty:\n",
    "                yi = int(di.iloc[0].year)\n",
    "                if years[0] <= yi <= years[-1]:\n",
    "                    val = ratio_by_year.get(yi, np.nan)\n",
    "                    if pd.notna(val):\n",
    "                        xs_i.append(yi); ys_i.append(val); labels_i.append(code)\n",
    "\n",
    "            if not dfim.empty:\n",
    "                yf = int(dfim.iloc[0].year)\n",
    "                if years[0] <= yf <= years[-1]:\n",
    "                    val = ratio_by_year.get(yf, np.nan)\n",
    "                    if pd.notna(val):\n",
    "                        xs_f.append(yf); ys_f.append(val); labels_f.append(code)\n",
    "\n",
    "        if xs_i:\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=xs_i, y=ys_i, mode='markers+text',\n",
    "                name='Início (selecionados)',\n",
    "                text=labels_i, textposition='top center',\n",
    "                marker=dict(symbol='circle', size=14, line=dict(width=2, color='black'))\n",
    "            ))\n",
    "        if xs_f:\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=xs_f, y=ys_f, mode='markers+text',\n",
    "                name='Fim (selecionados)',\n",
    "                text=labels_f, textposition='bottom center',\n",
    "                marker=dict(symbol='diamond', size=14, line=dict(width=2, color='black'))\n",
    "            ))\n",
    "\n",
    "    # 7) layout\n",
    "    fig.update_layout(\n",
    "        title='Mortes / Total de fundos por ano (com bolhas de Início/Fim dos selecionados)',\n",
    "        template='plotly_white',\n",
    "        xaxis_title='Ano',\n",
    "        yaxis_title='Mortes / Total',\n",
    "        height=440,\n",
    "        legend=dict(orientation='h', yanchor='bottom', y=1.02, xanchor='left', x=0)\n",
    "    )\n",
    "    fig.update_xaxes(dtick=1, tickformat='d')\n",
    "    fig.update_yaxes(tickformat='.4f')\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# no bloco de execução local:\n",
    "if __name__ == \"__main__\":\n",
    "    import os\n",
    "    PORT = int(os.environ.get(\"PORT\") or 8080)  # usa 8080 se PORT estiver vazia\n",
    "    app.run(host=\"0.0.0.0\", port=PORT, debug=False, use_reloader=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
